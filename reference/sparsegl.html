<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Fits regularization paths for sparse group-lasso penalized learning problems at a
sequence of regularization parameters lambda."><title>Regularization paths for sparse group-lasso models — sparsegl • sparsegl</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Regularization paths for sparse group-lasso models — sparsegl"><meta property="og:description" content="Fits regularization paths for sparse group-lasso penalized learning problems at a
sequence of regularization parameters lambda."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">sparsegl</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.5.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item">
  <a class="nav-link" href="../articles/sparsegl.html">Get started</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/dajmcdon/sparsegl/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Regularization paths for sparse group-lasso models</h1>
      <small class="dont-index">Source: <a href="https://github.com/dajmcdon/sparsegl/blob/HEAD/R/sparsegl.R" class="external-link"><code>R/sparsegl.R</code></a></small>
      <div class="d-none name"><code>sparsegl.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Fits regularization paths for sparse group-lasso penalized learning problems at a
sequence of regularization parameters <code>lambda</code>.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">sparsegl</span><span class="op">(</span></span>
<span>  <span class="va">x</span>,</span>
<span>  <span class="va">y</span>,</span>
<span>  group <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gaussian"</span>, <span class="st">"binomial"</span><span class="op">)</span>,</span>
<span>  nlambda <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  lambda.factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">nobs</span> <span class="op">&lt;</span> <span class="va">nvars</span>, <span class="fl">0.01</span>, <span class="fl">1e-04</span><span class="op">)</span>,</span>
<span>  lambda <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  pf_group <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">bs</span><span class="op">)</span>,</span>
<span>  pf_sparse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">nvars</span><span class="op">)</span>,</span>
<span>  intercept <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  asparse <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>  standardize <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  lower_bnd <span class="op">=</span> <span class="op">-</span><span class="cn">Inf</span>,</span>
<span>  upper_bnd <span class="op">=</span> <span class="cn">Inf</span>,</span>
<span>  dfmax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">group</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1L</span>,</span>
<span>  pmax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">dfmax</span> <span class="op">*</span> <span class="fl">1.2</span>, <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">group</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  eps <span class="op">=</span> <span class="fl">1e-08</span>,</span>
<span>  maxit <span class="op">=</span> <span class="fl">3e+08</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>x</dt>
<dd><p>Double. A matrix of predictors, of dimension
\(n \times p\); each row
is a vector of measurements and each column is a feature. Objects of class
<code><a href="https://rdrr.io/pkg/Matrix/man/sparseMatrix.html" class="external-link">Matrix::sparseMatrix</a></code> are supported.</p></dd>


<dt>y</dt>
<dd><p>Double/Integer/Factor. The response variable.
Quantitative for <code>family="gaussian"</code>.
For <code>family="binomial"</code> should be either a factor with two levels or
a vector of integers taking 2 unique values.
For a factor, the last level in alphabetical order is the target class.</p></dd>


<dt>group</dt>
<dd><p>Integer. A vector of consecutive integers describing the
grouping of the coefficients (see example below).</p></dd>


<dt>family</dt>
<dd><p>Character. Specifies the loss function to use, valid
options are:</p><ul><li><p><code>"gaussian"</code> - least squares loss (regression, the default),</p></li>
<li><p><code>"binomial"</code> - logistic loss (classification)</p></li>
</ul></dd>


<dt>nlambda</dt>
<dd><p>The number of <code>lambda</code> values - default is 100.</p></dd>


<dt>lambda.factor</dt>
<dd><p>The factor for getting the minimal lambda in the
<code>lambda</code> sequence, where <code>min(lambda) = lambda.factor * max(lambda)</code>.
<code>max(lambda)</code> is the smallest value of <code>lambda</code> for which all coefficients
are zero. The default depends on the relationship between \(n\)
(the number of rows in the matrix of predictors) and \(p\)
(the number of predictors). If \(n \geq p\), the
default is <code>0.0001</code>.  If \(n &lt; p\), the default is <code>0.01</code>.
A very small value of <code>lambda.factor</code> will lead to a
saturated fit. This argument has no effect if there is user-defined
<code>lambda</code> sequence.</p></dd>


<dt>lambda</dt>
<dd><p>A user supplied <code>lambda</code> sequence. The default, <code>NULL</code>
results in an automatic computation based on <code>nlambda</code>, the smallest value
of <code>lambda</code> that would give the null model (all coefficient estimates equal
to zero), and <code>lambda.factor</code>. Supplying a value of <code>lambda</code> overrides
this behaviour. It is likely better to supply a
decreasing sequence of <code>lambda</code> values than a single (small) value. If
supplied, the user-defined <code>lambda</code> sequence is automatically sorted in
decreasing order.</p></dd>


<dt>pf_group</dt>
<dd><p>Penalty factor on the groups, a vector of the same
length as the total number of groups. Separate penalty weights can be applied
to each group of \(\beta\)s to allow differential shrinkage.
Can be 0 for some
groups, which implies no shrinkage, and results in that group always being
included in the model (depending on <code>pf_sparse</code>). Default value for each
entry is the square-root of the corresponding size of each group.</p></dd>


<dt>pf_sparse</dt>
<dd><p>Penalty factor on l1-norm, a vector the same length as the
total number of columns in <code>x</code>. Each value corresponds to one predictor
Can be 0 for some predictors, which
implies that predictor will be receive by the group l2-norm penalty.
Each entry should be non-negative in this vector.</p></dd>


<dt>intercept</dt>
<dd><p>Whether to include intercept in the model. Default is TRUE.</p></dd>


<dt>asparse</dt>
<dd><p>The weight to put on the \(\ell_1\)-norm in sparse group
lasso. Default is <code>0.05</code>.</p></dd>


<dt>standardize</dt>
<dd><p>Logical flag for variable standardization (scaling) prior
to fitting the model. Default is TRUE.</p></dd>


<dt>lower_bnd</dt>
<dd><p>Lower bound for coefficient values, a vector in length of 1
or of length the number of groups. Must be non-positive numbers only.
Default value for each entry is <code>-Inf</code>.</p></dd>


<dt>upper_bnd</dt>
<dd><p>Upper for coefficient values, a vector in length of 1
or of length the number of groups. Must be non-negative numbers only.
Default value for each entry is <code>Inf</code>.</p></dd>


<dt>dfmax</dt>
<dd><p>Limit the maximum number of groups in the model. Default is
no limit.</p></dd>


<dt>pmax</dt>
<dd><p>Limit the maximum number of groups ever to be nonzero. For
example once a group enters the model, no matter how many times it exits or
re-enters model through the path, it will be counted only once.</p></dd>


<dt>eps</dt>
<dd><p>Convergence termination tolerance. Defaults value is <code>1e-8</code>.</p></dd>


<dt>maxit</dt>
<dd><p>Maximum number of outer-loop iterations allowed at fixed lambda
value. Default is <code>3e8</code>. If models do not converge, consider increasing
<code>maxit</code>.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>An object with S3 class <code>sparsegl()</code>.</p><ul><li><p><code>call</code> The call that produced this object.</p></li>
<li><p><code>b0</code> Intercept sequence of length <code>length(lambda)</code>.</p></li>
<li><p><code>beta</code> A <code>p</code> x <code>length(lambda)</code> sparse matrix of coefficients.</p></li>
<li><p><code>df</code> The number of features with nonzero coefficients for each value of
<code>lambda</code>.</p></li>
<li><p><code>dim</code> Dimension of coefficient matrix.</p></li>
<li><p><code>lambda</code> The actual sequence of <code>lambda</code> values used.</p></li>
<li><p><code>npasses</code> Total number of iterations summed over all <code>lambda</code> values.</p></li>
<li><p><code>jerr</code> Error flag, for warnings and errors, 0 if no error.</p></li>
<li><p><code>group</code> A vector of consecutive integers describing the grouping of the
coefficients.</p></li>
<li><p><code>nobs</code> The number of observations used to estimate the model.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Note that the objective function for least squares is
$$RSS/(2n) + \lambda penalty$$
Users can also tweak the penalty by choosing a different penalty factor.</p>
<p>For computing speed reason, if models are not converging or running slowly,
consider increasing <code>eps</code>, decreasing <code>nlambda</code>, or increasing
<code>lambda.factor</code> before increasing <code>maxit</code>.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="plot.sparsegl.html">plot.sparsegl()</a></code>, <code><a href="coef.sparsegl.html">coef.sparsegl()</a></code>, <code><a href="predict.sparsegl.html">predict.sparsegl()</a></code>
and <code><a href="print.sparsegl.html">print.sparsegl()</a></code> methods.</p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span></span></span>
<span class="r-in"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">20</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">eps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">beta_star</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="op">-</span><span class="fl">5</span>, <span class="fl">2</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="op">(</span><span class="va">p</span> <span class="op">-</span> <span class="fl">15</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta_star</span> <span class="op">+</span> <span class="va">eps</span></span></span>
<span class="r-in"><span><span class="va">groups</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">p</span> <span class="op">/</span> <span class="fl">5</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">sparsegl</span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, group <span class="op">=</span> <span class="va">groups</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Daniel J. McDonald, Xiaoxuan Liang, Aaron Cohen.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer></div>

  

  

  </body></html>

