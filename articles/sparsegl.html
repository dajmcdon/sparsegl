<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Getting started with sparsegl ‚Ä¢ sparsegl</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="‚Äùimage/svg+xml‚Äù" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Getting started with sparsegl">
<meta name="description" content="An introductory tutorial with examples">
<meta property="og:description" content="An introductory tutorial with examples">
<meta property="og:image" content="https://dajmcdon.github.io/sparsegl/logo.png">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">sparsegl</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.1.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/sparsegl.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/dajmcdon/sparsegl/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Getting started with sparsegl</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/dajmcdon/sparsegl/blob/main/vignettes/sparsegl.Rmd" class="external-link"><code>vignettes/sparsegl.Rmd</code></a></small>
      <div class="d-none name"><code>sparsegl.Rmd</code></div>
    </div>

    
    
<p>This package provides tools for fitting regularization paths for
sparse group-lasso penalized learning problems. The model is fit for a
sequence of the regularization parameters.</p>
<p>The strengths and improvements that this package offers relative to
other sparse group-lasso packages are as follows:</p>
<ul>
<li><p>Compiled Fortran code significantly speeds up the sparse
group-lasso estimation process.</p></li>
<li><p>So-called ‚Äústrong rules‚Äù are implemented during group wise
coordinate descent steps screen out groups which are likely to be 0 at
the solution.</p></li>
<li><p>The design matrix <code>X</code> may be a sparse.</p></li>
<li><p>An <code><a href="../reference/estimate_risk.html">estimate_risk()</a></code> function may be used to evaluate
the quality of fitted models via information criteria, providing a means
for model selection if cross-validation is too computationally
costly.</p></li>
<li><p>Additional exponential families may be fit (though this is
typically slower).</p></li>
</ul>
<p>For additional details, see Liang, Cohen, S√≥lon Heinsfeld, Pestilli,
and McDonald (<a href="#ref-sparsegl">2024</a>).</p>
<div class="section level2">
<h2 id="installing">Installing<a class="anchor" aria-label="anchor" href="#installing"></a>
</h2>
<p>You can install the released version of <a href="https://github.com/dajmcdon/sparsegl" class="external-link">sparsegl</a> from
<a href="https://CRAN.R-project.org" class="external-link">CRAN</a> with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"sparsegl"</span><span class="op">)</span></span></code></pre></div>
<p>You can install the development version from <a href="https://github.com/" class="external-link">GitHub</a> with:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("remotes")</span></span>
<span><span class="fu">remotes</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"dajmcdon/sparsegl"</span><span class="op">)</span></span></code></pre></div>
<p>Vignettes are not included in the package by default. If you want to
include vignettes, then use this modified command:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">remotes</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span></span>
<span>  <span class="st">"dajmcdon/sparsegl"</span>,</span>
<span>  build_vignettes <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>  dependencies <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>For this getting-started vignette, first, we will randomly generate
<code>X</code>, an input matrix of predictors of dimension
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">n\times p</annotation></semantics></math>.
To create <code>y</code>, a real-valued vector, we use either a</p>
<ul>
<li>Linear Regression model:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>X</mi><msup><mi>Œ≤</mi><mo>*</mo></msup><mo>+</mo><mi>œµ</mi></mrow><annotation encoding="application/x-tex">y = X\beta^* + \epsilon</annotation></semantics></math>.</li>
<li>Logistic regression model:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><mi>‚ãØ</mi><mo>,</mo><msub><mi>y</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y = (y_1, y_2, \cdots, y_n)</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>‚àº</mo><mtext mathvariant="normal">Bernoulli</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><msubsup><mi>x</mi><mi>i</mi><mi>‚ä§</mi></msubsup><msup><mi>Œ≤</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y_i \sim \text{Bernoulli}\left(\frac{1}{1 + \exp(-x_i^\top \beta^*)}\right)</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>‚ãØ</mi><mo>,</mo><mi>n</mi><mi>.</mi></mrow><annotation encoding="application/x-tex">i = 1, 2, \cdots, n.</annotation></semantics></math>
</li>
</ul>
<p>where the coefficient vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Œ≤</mi><mo>*</mo></msup><annotation encoding="application/x-tex">\beta^*</annotation></semantics></math>
is specified as below, and the white noise
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œµ</mi><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math>
follows a standard normal distribution. Then the sparse group-lasso
problem is formulated as the sum of mean squared error (linear
regression) or logistic loss (logistic regression) and a convex
combination of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>‚Ñì</mo><mn>1</mn></msub><annotation encoding="application/x-tex">\ell_1</annotation></semantics></math>
lasso penalty with an
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>‚Ñì</mo><mn>2</mn></msub><annotation encoding="application/x-tex">\ell_2</annotation></semantics></math>
group lasso penalty:</p>
<ul>
<li>Linear regression:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mrow><mi>Œ≤</mi><mo>‚àà</mo><msup><mi>‚Ñù</mi><mi>p</mi></msup></mrow></munder><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>n</mi></mrow></mfrac><mo stretchy="false" form="postfix">‚à•</mo><mi>y</mi><mo>‚àí</mo><munder><mo>‚àë</mo><mi>g</mi></munder><msup><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><msup><mi>Œ≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><msubsup><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>Œª</mi><munder><mo>‚àë</mo><mi>g</mi></munder><msqrt><mrow><mo stretchy="true" form="prefix">|</mo><mi>g</mi><mo stretchy="true" form="postfix">|</mo></mrow></msqrt><mo stretchy="false" form="postfix">‚à•</mo><msup><mi>Œ≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn></msub><mo>+</mo><mi>Œ±</mi><mi>Œª</mi><mo stretchy="false" form="postfix">‚à•</mo><mi>Œ≤</mi><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mo>*</mo><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\min_{\beta\in\mathbb{R}^p}\left(\frac{1}{2n} \rVert y - \sum_g X^{(g)}\beta^{(g)}\rVert_2^2 + (1-\alpha)\lambda\sum_g \sqrt{|g|}\rVert\beta^{(g)}\rVert_2 + \alpha\lambda\rVert\beta\rVert_1 \right) \qquad (*).
</annotation></semantics></math>
</li>
<li>Logistic regression:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mrow><mi>Œ≤</mi><mo>‚àà</mo><msup><mi>‚Ñù</mi><mi>p</mi></msup></mrow></munder><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>n</mi></mrow></mfrac><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>+</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><msub><mi>y</mi><mi>i</mi></msub><msubsup><mi>x</mi><mi>i</mi><mi>‚ä§</mi></msubsup><mi>Œ≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>Œª</mi><munder><mo>‚àë</mo><mi>g</mi></munder><msqrt><mrow><mo stretchy="true" form="prefix">|</mo><mi>g</mi><mo stretchy="true" form="postfix">|</mo></mrow></msqrt><mo stretchy="false" form="postfix">‚à•</mo><msup><mi>Œ≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn></msub><mo>+</mo><mi>Œ±</mi><mi>Œª</mi><mo stretchy="false" form="postfix">‚à•</mo><mi>Œ≤</mi><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mo>*</mo><mo>*</mo><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\min_{\beta\in\mathbb{R}^p}\left(\frac{1}{2n}\sum_{i=1}^n \log\left(1 + \exp\left(-y_ix_i^\top\beta\right)\right) + (1-\alpha)\lambda\sum_g \sqrt{|g|}\rVert\beta^{(g)}\rVert_2 + \alpha\lambda\rVert\beta\rVert_1 \right) \qquad (**).
</annotation></semantics></math>
</li>
</ul>
<p>where</p>
<ul>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">X^{(g)}</annotation></semantics></math>
is the submatrix of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
with columns corresponding to the features in group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>.</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Œ≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\beta^{(g)}</annotation></semantics></math>
is the corresponding coefficients of the features in group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>.</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">|</mo><mi>g</mi><mo stretchy="true" form="postfix">|</mo></mrow><annotation encoding="application/x-tex">|g|</annotation></semantics></math>
is the number of predictors in group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>.</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
adjusts the weight between lasso penalty and group-lasso
penalty.</p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
fine-tunes the size of penalty imposed on the model to control the
number of nonzero coefficients.</p></li>
</ul>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dajmcdon/sparsegl" class="external-link">sparsegl</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1010</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">200</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">beta_star</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="op">-</span><span class="fl">5</span>, <span class="fl">2</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="op">-</span><span class="fl">3</span>, <span class="fl">8</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="op">(</span><span class="va">p</span> <span class="op">-</span> <span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">groups</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">p</span> <span class="op">/</span> <span class="fl">5</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Linear regression model</span></span>
<span><span class="va">eps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta_star</span> <span class="op">+</span> <span class="va">eps</span></span>
<span></span>
<span><span class="co"># Logistic regression model</span></span>
<span><span class="va">pr</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta_star</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y_binary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="va">pr</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="sparsegl">
<code>sparsegl()</code><a class="anchor" aria-label="anchor" href="#sparsegl"></a>
</h2>
<p>Given an input matrix <code>X</code>, and a response vector
<code>y</code>, a sparse group-lasso regularized linear model is
estimated for a sequence of penalty parameter values. The penalty is
composed of lasso penalty and group lasso penalty. The other main
arguments the users might supply are:</p>
<ul>
<li><p><code>group</code>: a vector with consecutive integers of length
<code>p</code> indicating the grouping of the features. By default, each
group only contains one feature if without initialization.</p></li>
<li><p><code>family</code>: A character string specifying the likelihood
to use, could be either linear regression <code>"gaussian"</code> or
logistic regression loss <code>"binomial"</code>. Default is
<code>"gaussian"</code>. If other exponential families are required, a
<code><a href="https://rdrr.io/r/stats/family.html" class="external-link">stats::family()</a></code> object may be used
(e.g.¬†<code><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson()</a></code>). In that case, arguments providing
observation weights or offset terms are allowed as well.</p></li>
<li><p><code>pf_group</code>: Separate penalty weights can be applied to
each group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ≤</mi><mi>g</mi></msub><annotation encoding="application/x-tex">\beta_g</annotation></semantics></math>
to allow differential shrinkage. Can be 0 for some groups, which implies
no shrinkage. The default value for each entry is the square-root of the
corresponding size of each group.</p></li>
<li><p><code>pf_sparse</code>: Penalty factor on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>‚Ñì</mo><mn>1</mn></msub><annotation encoding="application/x-tex">\ell_1</annotation></semantics></math>-norm,
a vector the same length as the total number of columns in x. Each value
corresponds to one predictor Can be 0 for some predictors, which implies
that predictor will be receive only the group penalty.</p></li>
<li><p><code>asparse</code>: changes the weight of lasso penalty,
referring to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mo>*</mo><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(*)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mo>*</mo><mo>*</mo><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(**)</annotation></semantics></math>
above: <code>asparse</code> =
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>
gives the lasso penalty only. <code>asparse</code> =
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math>
gives the group lasso penalty only. The default value of
<code>asparse</code> is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0.05</mn><annotation encoding="application/x-tex">0.05</annotation></semantics></math>.</p></li>
<li><p><code>lower_bnd</code>: lower bound for coefficient values, a
vector in length of 1 or the number of groups including non-positive
numbers only. Default value for each entry is
-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚àû</mi><annotation encoding="application/x-tex">\infty</annotation></semantics></math>.</p></li>
<li><p><code>upper_bnd</code>: upper bound for coefficient values, a
vector in length of 1 or the number of groups including non-negative
numbers only. Default value for each entry is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚àû</mi><annotation encoding="application/x-tex">\infty</annotation></semantics></math>.</p></li>
</ul>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sparsegl.html">sparsegl</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, group <span class="op">=</span> <span class="va">groups</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="plotting-sparsegl-objects">Plotting <code>sparsegl</code> objects<a class="anchor" aria-label="anchor" href="#plotting-sparsegl-objects"></a>
</h3>
<p>This function displays nonzero coefficient curves for each penalty
parameter <code>lambda</code> values in the regularization path for a
fitted <code>sparsegl</code> object. The arguments of this function
are:</p>
<ul>
<li><p><code>y_axis</code>: can be set with either <code>"coef"</code>
or <code>"group"</code>. Default is <code>"coef"</code>.</p></li>
<li><p><code>x_axis</code>: can be set with either <code>"lambda"</code>
or <code>"penalty"</code>. Default is <code>"lambda"</code>.</p></li>
</ul>
<p>To elaborate on these arguments:</p>
<ul>
<li><p>The plot with <code>y_axis = "group"</code> shows the group norms
against the log-<code>lambda</code> or the scaled group norm vector.
Each group norm is defined by:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ±</mi><mo stretchy="false" form="postfix">‚à•</mo><msup><mi>Œ≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>1</mn></msub><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><munder><mo>‚àë</mo><mi>g</mi></munder><mo stretchy="false" form="postfix">‚à•</mo><msup><mi>Œ≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">
\alpha\rVert\beta^{(g)}\rVert_1 + (1 - \alpha)\sum_g\rVert\beta^{(g)}\rVert_2
</annotation></semantics></math> Curves are plotted in the same color if
the corresponding features are in the same group. Note that the number
of curves shown on the plots may be less than the actual number of
groups since only the groups containing nonzero features for at least
one
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
in the sequence are included.</p></li>
<li><p>The plot with <code>y_axis = "coef"</code> shows the estimated
coefficients against the <code>lambda</code> or the scaled group norm.
Again, only the features with nonzero estimates for at least one
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
value in the sequence are displayed.</p></li>
<li><p>The plot with <code>x_axis = "lambda"</code> indicates the
<code>x_axis</code> displays
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\log(\lambda)</annotation></semantics></math>.</p></li>
<li><p>The plot with <code>x_axis = "penalty"</code> indicates the
<code>x_axis</code> displays the scaled group norm vector. Each element
in this vector is defined by:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mrow><mi>Œ±</mi><mo stretchy="false" form="postfix">‚à•</mo><mi>Œ≤</mi><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>1</mn></msub><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><munder><mo>‚àë</mo><mi>g</mi></munder><mo stretchy="false" form="postfix">‚à•</mo><msup><mi>Œ≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn></msub></mrow><mrow><munder><mo>max</mo><mi>Œ≤</mi></munder><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ±</mi><mo stretchy="false" form="postfix">‚à•</mo><mi>Œ≤</mi><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>1</mn></msub><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><munder><mo>‚àë</mo><mi>g</mi></munder><mo stretchy="false" form="postfix">‚à•</mo><msup><mi>Œ≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><msub><mo stretchy="false" form="postfix">‚à•</mo><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><annotation encoding="application/x-tex">
\frac{\alpha\rVert \beta\rVert_1 + (1-\alpha)\sum_g\rVert \beta^{(g)}\rVert_2}{\max_\beta\left(\alpha \rVert \beta\rVert_1 + (1-\alpha)\sum_g\rVert \beta^{(g)}\rVert_2\right)}
</annotation></semantics></math></p></li>
</ul>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit1</span>, y_axis <span class="op">=</span> <span class="st">"group"</span>, x_axis <span class="op">=</span> <span class="st">"lambda"</span><span class="op">)</span></span></code></pre></div>
<p><img src="sparsegl_files/figure-html/unnamed-chunk-7-1.png" width="768"></p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit1</span>, y_axis <span class="op">=</span> <span class="st">"coef"</span>, x_axis <span class="op">=</span> <span class="st">"penalty"</span>, add_legend <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p><img src="sparsegl_files/figure-html/unnamed-chunk-7-2.png" width="768"></p>
</div>
</div>
<div class="section level2">
<h2 id="cv-sparsegl">
<code>cv.sparsegl()</code><a class="anchor" aria-label="anchor" href="#cv-sparsegl"></a>
</h2>
<p>This function performs k-fold cross-validation (cv). It takes the
same arguments <code>X</code>, <code>y</code>, <code>group</code>, which
are specified above, with additional argument <code>pred.loss</code> for
the error measure. Options are <code>"default"</code>,
<code>"mse"</code>, <code>"deviance"</code>, <code>"mae"</code>, and
<code>"misclass"</code>. With <code>family = "gaussian"</code>,
<code>"default"</code> is equivalent to <code>"mse"</code> and
<code>"deviance"</code>. In general, <code>"deviance"</code> will give
the negative log-likelihood. The option <code>"misclass"</code> is only
available if <code>family = "binomial"</code>.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_l1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.sparsegl.html">cv.sparsegl</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, group <span class="op">=</span> <span class="va">groups</span>, pred.loss <span class="op">=</span> <span class="st">"mae"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_l1</span><span class="op">)</span></span></code></pre></div>
<p><img src="sparsegl_files/figure-html/unnamed-chunk-8-1.png" width="768"></p>
<div class="section level3">
<h3 id="methods">Methods<a class="anchor" aria-label="anchor" href="#methods"></a>
</h3>
<p>A number of S3 methods are provided for both <code>sparsegl</code>
and <code>cv.sparsegl</code> objects.</p>
<ul>
<li>
<code><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef()</a></code> and <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> return a matrix of
coefficients and predictions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math>
given a matrix <code>X</code> at each lambda respectively. The optional
<code>s</code> argument may provide a specific value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
(not necessarily part of the original sequence), or, in the case of a
<code>cv.sparsegl</code> object, a string specifying either
<code>"lambda.min"</code> or <code>"lambda.1se"</code>.</li>
</ul>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">coef</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit1</span>, s <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.02</span>, <span class="fl">0.03</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit1</span>, newx <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fl">100</span>, <span class="op">]</span>, s <span class="op">=</span> <span class="va">fit1</span><span class="op">$</span><span class="va">lambda</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt;             s1        s2</span></span>
<span><span class="co">#&gt; [1,] -4.071804 -4.091689</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit_l1</span>, newx <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fl">100</span>, <span class="op">]</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span><span class="co">#&gt;             s1</span></span>
<span><span class="co">#&gt; [1,] -15.64857</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  sparsegl(x = X, y = y, group = groups) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Summary of Lambda sequence:</span></span>
<span><span class="co">#&gt;          lambda index nnzero active_grps</span></span>
<span><span class="co">#&gt; Max.    0.62948     1      0           0</span></span>
<span><span class="co">#&gt; 3rd Qu. 0.19676    26     20           4</span></span>
<span><span class="co">#&gt; Median  0.06443    50     19           4</span></span>
<span><span class="co">#&gt; 1st Qu. 0.02014    75     25           5</span></span>
<span><span class="co">#&gt; Min.    0.00629   100    111          23</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="estimate_risk">
<code>estimate_risk()</code><a class="anchor" aria-label="anchor" href="#estimate_risk"></a>
</h2>
<p>With extremely large data sets, cross validation may be to slow for
tuning parameter selection. This function uses the degrees of freedom to
calculate various information criteria. This function uses the ‚Äúunknown
variance‚Äù version of the likelihood. Only implemented for Gaussian
regression. The constant is ignored (as in
<code><a href="https://rdrr.io/r/stats/extractAIC.html" class="external-link">stats::extractAIC()</a></code>).</p>
<ul>
<li><p><code>object</code>: a fitted <code>sparsegl</code>
object.</p></li>
<li>
<p><code>type</code>: three types of penalty used for
calculation:</p>
<ul>
<li><p>AIC (Akaike information criterion):
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>d</mi><mi>f</mi><mi>/</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">2 df / n</annotation></semantics></math></p></li>
<li><p>BIC (Bayesian information criterion):
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>d</mi><mi>f</mi><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">2 df\log(n) / n</annotation></semantics></math></p></li>
<li><p>GCV (Generalized cross validation):
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>‚àí</mo><mn>2</mn><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>d</mi><mi>f</mi><mi>/</mi><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">-2\log(1 - df / n)</annotation></semantics></math></p></li>
</ul>
</li>
</ul>
<p>where df is the degree-of-freedom, and n is the sample size.</p>
<ul>
<li>
<code>approx_df</code>: indicates if an approximation to the correct
degree-of-freedom at each penalty parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
should used. Default is <code>FALSE</code> and the program will compute
an unbiased estimate of the exact degree-of-freedom.</li>
</ul>
<p>The <code>df</code> component of a <code>sparsegl</code> object is an
approximation (albeit a fairly accurate one) to the actual
degrees-of-freedom. However, computing the exact value requires
inverting a portion of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ùêó</mi><mi>‚ä§</mi></msup><mi>ùêó</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}^\top \mathbf{X}</annotation></semantics></math>.
So this computation may take some time (the default computes the exact
df). For more details about how this formula, see Vaiter, Deledalle,
Peyr√©, et al., (<a href="#ref-vaiter">2012</a>).</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">risk</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/estimate_risk.html">estimate_risk</a></span><span class="op">(</span><span class="va">fit1</span>, <span class="va">X</span>, approx_df <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p><img src="sparsegl_files/figure-html/unnamed-chunk-11-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references">
<div id="ref-sparsegl">
<p>Liang, X., Cohen, A., S√≥lon Heinsfeld, A., Pestilli, F., and
McDonald, D.J. 2024. ‚Äúsparsegl: An <code>R</code> Package for Estimating
Sparse Group Lasso.‚Äù <em>Journal of Statistical Software</em> 110(6),
1‚Äì23. <a href="https://doi.org/10.18637/jss.v110.i06" class="external-link uri">https://doi.org/10.18637/jss.v110.i06</a>.</p>
</div>
<div id="ref-vaiter">
<p>Vaiter S, Deledalle C, Peyr√© G, Fadili J, and Dossal C. 2012. ‚ÄúThe
Degrees of Freedom of the Group Lasso for a General Design.‚Äù <a href="https://arxiv.org/abs/1212.6478" class="external-link uri">https://arxiv.org/abs/1212.6478</a>.</p>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Daniel J. McDonald, Xiaoxuan Liang, Anibal Sol√≥n Heinsfeld, Aaron Cohen.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
