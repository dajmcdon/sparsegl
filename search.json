[{"path":"https://dajmcdon.github.io/sparsegl/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 sparsegl authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"installing","dir":"Articles","previous_headings":"","what":"Installing","title":"Getting started with sparsegl","text":"can install released version sparsegl CRAN : can install development version GitHub : Vignettes included package default. want include vignettes, use modified command: getting-started vignette, first, randomly generate X, input matrix predictors dimension n×pn\\times p. create y, real-valued vector, use either Linear Regression model: y=Xβ*+ϵy = X\\beta^* + \\epsilon. Logistic regression model: y=(y1,y2,⋯,yn)y = (y_1, y_2, \\cdots, y_n), yi∼Bernoulli(11+exp(−xi⊤β*))y_i \\sim \\text{Bernoulli}\\left(\\frac{1}{1 + \\exp(-x_i^\\top \\beta^*)}\\right), =1,2,⋯,n.= 1, 2, \\cdots, n. coefficient vector β*\\beta^* specified , white noise ϵ\\epsilon follows standard normal distribution. sparse group-lasso problem formulated sum mean squared error (linear regression) logistic loss (logistic regression) convex combination ℓ1\\ell_1 lasso penalty ℓ2\\ell_2 group lasso penalty: Linear regression: minβ∈ℝp(12n∥y−∑gX(g)β(g)∥22+(1−α)λ∑g|g|∥β(g)∥2+αλ∥β∥1)(*). \\min_{\\beta\\\\mathbb{R}^p}\\left(\\frac{1}{2n} \\rVert y - \\sum_g X^{(g)}\\beta^{(g)}\\rVert_2^2 + (1-\\alpha)\\lambda\\sum_g \\sqrt{|g|}\\rVert\\beta^{(g)}\\rVert_2 + \\alpha\\lambda\\rVert\\beta\\rVert_1 \\right) \\qquad (*). Logistic regression: minβ∈ℝp(12n∑=1nlog(1+exp(−yixi⊤β))+(1−α)λ∑g|g|∥β(g)∥2+αλ∥β∥1)(**). \\min_{\\beta\\\\mathbb{R}^p}\\left(\\frac{1}{2n}\\sum_{=1}^n \\log\\left(1 + \\exp\\left(-y_ix_i^\\top\\beta\\right)\\right) + (1-\\alpha)\\lambda\\sum_g \\sqrt{|g|}\\rVert\\beta^{(g)}\\rVert_2 + \\alpha\\lambda\\rVert\\beta\\rVert_1 \\right) \\qquad (**). X(g)X^{(g)} submatrix XX columns corresponding features group gg. β(g)\\beta^{(g)} corresponding coefficients features group gg. |g||g| number predictors group gg. α\\alpha adjusts weight lasso penalty group-lasso penalty. λ\\lambda fine-tunes size penalty imposed model control number nonzero coefficients.","code":"install.packages(\"sparsegl\") # install.packages(\"remotes\") remotes::install_github(\"dajmcdon/sparsegl\") remotes::install_github(   \"dajmcdon/sparsegl\",   build_vignettes = TRUE,    dependencies = TRUE ) library(sparsegl) set.seed(1010) n <- 100 p <- 200 X <- matrix(data = rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p) beta_star <- c(   rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5),   c(2, -3, 8, 0, 0), rep(0, (p - 20)) ) groups <- rep(1:(p / 5), each = 5)  # Linear regression model eps <- rnorm(n, mean = 0, sd = 1) y <- X %*% beta_star + eps  # Logistic regression model pr <- 1 / (1 + exp(-X %*% beta_star)) y_binary <- rbinom(n, 1, pr)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"sparsegl","dir":"Articles","previous_headings":"","what":"sparsegl()","title":"Getting started with sparsegl","text":"Given input matrix X, response vector y, sparse group-lasso regularized linear model estimated sequence penalty parameter values. penalty composed lasso penalty group lasso penalty. main arguments users might supply : group: vector consecutive integers length p indicating grouping features. default, group contains one feature without initialization. family: character string specifying likelihood use, either linear regression \"gaussian\" logistic regression loss \"binomial\". Default \"gaussian\". exponential families required, stats::family() object may used (e.g. poisson()). case, arguments providing observation weights offset terms allowed well. pf_group: Separate penalty weights can applied group βg\\beta_g allow differential shrinkage. Can 0 groups, implies shrinkage. default value entry square-root corresponding size group. pf_sparse: Penalty factor ℓ1\\ell_1-norm, vector length total number columns x. value corresponds one predictor Can 0 predictors, implies predictor receive group penalty. asparse: changes weight lasso penalty, referring α\\alpha (*)(*) (**)(**) : asparse = 11 gives lasso penalty . asparse = 00 gives group lasso penalty . default value asparse 0.050.05. lower_bnd: lower bound coefficient values, vector length 1 number groups including non-positive numbers . Default value entry -∞\\infty. upper_bnd: upper bound coefficient values, vector length 1 number groups including non-negative numbers . Default value entry ∞\\infty.","code":"fit1 <- sparsegl(X, y, group = groups)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"plotting-sparsegl-objects","dir":"Articles","previous_headings":"sparsegl()","what":"Plotting sparsegl objects","title":"Getting started with sparsegl","text":"function displays nonzero coefficient curves penalty parameter lambda values regularization path fitted sparsegl object. arguments function : y_axis: can set either \"coef\" \"group\". Default \"coef\". x_axis: can set either \"lambda\" \"penalty\". Default \"lambda\". elaborate arguments: plot y_axis = \"group\" shows group norms log-lambda scaled group norm vector. group norm defined : α∥β(g)∥1+(1−α)∑g∥β(g)∥2 \\alpha\\rVert\\beta^{(g)}\\rVert_1 + (1 - \\alpha)\\sum_g\\rVert\\beta^{(g)}\\rVert_2  Curves plotted color corresponding features group. Note number curves shown plots may less actual number groups since groups containing nonzero features least one λ\\lambda sequence included. plot y_axis = \"coef\" shows estimated coefficients lambda scaled group norm. , features nonzero estimates least one λ\\lambda value sequence displayed. plot x_axis = \"lambda\" indicates x_axis displays log(λ)\\log(\\lambda). plot x_axis = \"penalty\" indicates x_axis displays scaled group norm vector. element vector defined : α∥β∥1+(1−α)∑g∥β(g)∥2maxβ(α∥β∥1+(1−α)∑g∥β(g)∥2) \\frac{\\alpha\\rVert \\beta\\rVert_1 + (1-\\alpha)\\sum_g\\rVert \\beta^{(g)}\\rVert_2}{\\max_\\beta\\left(\\alpha \\rVert \\beta\\rVert_1 + (1-\\alpha)\\sum_g\\rVert \\beta^{(g)}\\rVert_2\\right)}","code":"plot(fit1, y_axis = \"group\", x_axis = \"lambda\") plot(fit1, y_axis = \"coef\", x_axis = \"penalty\", add_legend = FALSE)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"cv-sparsegl","dir":"Articles","previous_headings":"","what":"cv.sparsegl()","title":"Getting started with sparsegl","text":"function performs k-fold cross-validation (cv). takes arguments X, y, group, specified , additional argument pred.loss error measure. Options \"default\", \"mse\", \"deviance\", \"mae\", \"misclass\". family = \"gaussian\", \"default\" equivalent \"mse\" \"deviance\". general, \"deviance\" give negative log-likelihood. option \"misclass\" available family = \"binomial\".","code":"fit_l1 <- cv.sparsegl(X, y, group = groups, pred.loss = \"mae\") plot(fit_l1)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"methods","dir":"Articles","previous_headings":"cv.sparsegl()","what":"Methods","title":"Getting started with sparsegl","text":"number S3 methods provided sparsegl cv.sparsegl objects. coef() predict() return matrix coefficients predictions ŷ\\hat{y} given matrix X lambda respectively. optional s argument may provide specific value λ\\lambda (necessarily part original sequence), , case cv.sparsegl object, string specifying either \"lambda.min\" \"lambda.1se\".","code":"coef <- coef(fit1, s = c(0.02, 0.03)) predict(fit1, newx = X[100, ], s = fit1$lambda[2:3]) #>             s1        s2 #> [1,] -4.071804 -4.091689 predict(fit_l1, newx = X[100, ], s = \"lambda.1se\") #>             s1 #> [1,] -15.64857 print(fit1) #>  #> Call:  sparsegl(x = X, y = y, group = groups)  #>  #> Summary of Lambda sequence: #>          lambda index nnzero active_grps #> Max.    0.62948     1      0           0 #> 3rd Qu. 0.19676    26     20           4 #> Median  0.06443    50     19           4 #> 1st Qu. 0.02014    75     25           5 #> Min.    0.00629   100    111          23"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"estimate_risk","dir":"Articles","previous_headings":"","what":"estimate_risk()","title":"Getting started with sparsegl","text":"extremely large data sets, cross validation may slow tuning parameter selection. function uses degrees freedom calculate various information criteria. function uses “unknown variance” version likelihood. implemented Gaussian regression. constant ignored (stats::extractAIC()). object: fitted sparsegl object. type: three types penalty used calculation: AIC (Akaike information criterion): 2df/n2 df / n BIC (Bayesian information criterion): 2dflog(n)/n2 df\\log(n) / n GCV (Generalized cross validation): −2log(1−df/n)-2\\log(1 - df / n) df degree--freedom, n sample size. approx_df: indicates approximation correct degree--freedom penalty parameter λ\\lambda used. Default FALSE program compute unbiased estimate exact degree--freedom. df component sparsegl object approximation (albeit fairly accurate one) actual degrees--freedom. However, computing exact value requires inverting portion 𝐗⊤𝐗\\mathbf{X}^\\top \\mathbf{X}. computation may take time (default computes exact df). details formula, see Vaiter, Deledalle, Peyré, et al., (2012).","code":"risk <- estimate_risk(fit1, X, approx_df = FALSE)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Getting started with sparsegl","text":"Liang, X., Cohen, ., Sólon Heinsfeld, ., Pestilli, F., McDonald, D.J. 2024. “sparsegl: R Package Estimating Sparse Group Lasso.” Journal Statistical Software 110(6), 1–23. https://doi.org/10.18637/jss.v110.i06. Vaiter S, Deledalle C, Peyré G, Fadili J, Dossal C. 2012. “Degrees Freedom Group Lasso General Design.” https://arxiv.org/abs/1212.6478.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel J. McDonald. Author, maintainer, copyright holder. Xiaoxuan Liang. Author. Anibal Solón Heinsfeld. Author. Aaron Cohen. Author. Yi Yang. Contributor. Hui Zou. Contributor. Jerome Friedman. Contributor. Trevor Hastie. Contributor. Rob Tibshirani. Contributor. Balasubramanian Narasimhan. Contributor. Kenneth Tay. Contributor. Noah Simon. Contributor. Junyang Qian. Contributor. James Yang. Contributor.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Liang X, Cohen , Solón Heinsfeld , Pestilli F, McDonald DJ (2024). “sparsegl: R Package Estimating Sparse Group Lasso.” Journal Statistical Software, 110(6), 1–23. doi:10.18637/jss.v110.i06.","code":"@Article{,   title = {{sparsegl}: An {R} Package for Estimating Sparse Group Lasso},   author = {Xiaoxuan Liang and Aaron Cohen and Anibal {Sol{\\'o}n Heinsfeld} and Franco Pestilli and Daniel J. McDonald},   journal = {Journal of Statistical Software},   year = {2024},   volume = {110},   number = {6},   pages = {1--23},   doi = {10.18637/jss.v110.i06}, }"},{"path":"https://dajmcdon.github.io/sparsegl/index.html","id":"sparsegl-","dir":"","previous_headings":"","what":"Sparse Group Lasso","title":"Sparse Group Lasso","text":"goal sparsegl fit regularization paths sparse group-lasso penalized learning problems. model typically fit sequence regularization parameters λ\\lambda. estimators minimize −ℓ(β|y,𝐗)+λ(1−α)∑g∈G∥βg∥2+λα∥β∥1. -\\ell(\\beta | y,\\ \\mathbf{X}) + \\lambda(1-\\alpha)\\sum_{g\\G} \\lVert\\beta_g\\rVert_2 + \\lambda\\alpha \\lVert\\beta\\rVert_1. main focus package case loglikelihood corresponds Gaussian logistic regression. also provide ability fit arbitrary GLMs using stats::family() objects. Details may found Liang, Cohen, Sólon Heinsfeld, Pestilli, McDonald (2024).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Sparse Group Lasso","text":"can install released version sparsegl CRAN : can install development version GitHub :","code":"install.packages(\"sparsegl\") # install.packages(\"remotes\") remotes::install_github(\"dajmcdon/sparsegl\")"},{"path":"https://dajmcdon.github.io/sparsegl/index.html","id":"minimal-example","dir":"","previous_headings":"","what":"Minimal Example","title":"Sparse Group Lasso","text":"","code":"set.seed(1010) n <- 100 p <- 200 X <- matrix(data = rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p) eps <- rnorm(n, mean = 0, sd = 1) beta_star <- c(   rep(5, 5), c(5, -5, 2, 0, 0),   rep(-5, 5), c(2, -3, 8, 0, 0), rep(0, (p - 20)) ) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) plot(fit1, y_axis = \"coef\", x_axis = \"penalty\", add_legend = FALSE)"},{"path":"https://dajmcdon.github.io/sparsegl/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Sparse Group Lasso","text":"Liang, X., Cohen, ., Sólon Heinsfeld, ., Pestilli, F., McDonald, D.J. 2024. “sparsegl: R Package Estimating Sparse Group Lasso.” Journal Statistical Software 110(6), 1–23. https://doi.org/10.18637/jss.v110.i06.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"function etracts coefficients cross-validated sparsegl() model, using stored \"sparsegl.fit\" object, optimal value chosen lambda.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"","code":"# S3 method for class 'cv.sparsegl' coef(object, s = c(\"lambda.1se\", \"lambda.min\"), ...)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"object Fitted cv.sparsegl() object. s Value(s) penalty parameter lambda coefficients desired. Default single value s = \"lambda.1se\" stored CV object (corresponding largest value lambda CV error estimate within 1 standard error minimum). Alternatively s = \"lambda.min\" can used (corresponding minimum cross validation error estimate). s numeric, taken value(s) lambda used. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"coefficients requested value(s) lambda.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) cv_fit <- cv.sparsegl(X, y, groups) coef(cv_fit, s = c(0.02, 0.03)) #> 21 x 2 sparse Matrix of class \"dgCMatrix\" #>                      s1          s2 #> (Intercept)  0.25058054  0.32798112 #> V1           4.69685440  4.61179702 #> V2           4.87498687  4.80778825 #> V3           4.79092864  4.70788964 #> V4           4.66068791  4.53530689 #> V5           4.63701728  4.47046037 #> V6           4.83517828  4.67359737 #> V7          -4.32100726 -4.09271636 #> V8           1.78185776  1.67848050 #> V9           0.04970934  0.08302102 #> V10          0.03184873  0.07964946 #> V11         -4.77143301 -4.67240455 #> V12         -4.92212465 -4.82991217 #> V13         -4.76996682 -4.59229699 #> V14         -4.95490098 -4.88966650 #> V15         -4.88915656 -4.79944906 #> V16          .           .          #> V17          .           .          #> V18          .           .          #> V19          .           .          #> V20          .           ."},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract model coefficients from a sparsegl object. — coef.sparsegl","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"Computes coefficients requested value(s) lambda sparsegl() object.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"","code":"# S3 method for class 'sparsegl' coef(object, s = NULL, ...)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"object Fitted sparsegl() object. s Value(s) penalty parameter lambda coefficients required. Default entire sequence. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"coefficients requested values lambda.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"s new vector lambda values predictions requested. s lambda sequence used fitting model, coef function use linear interpolation make predictions. new values interpolated using fraction coefficients left right lambda indices.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) coef(fit1, s = c(0.02, 0.03)) #> 21 x 2 sparse Matrix of class \"dgCMatrix\" #>                      s1          s2 #> (Intercept) -0.01678224 -0.01682395 #> V1           4.91479976  4.80927045 #> V2           4.69948041  4.63159288 #> V3           4.74904120  4.59195270 #> V4           4.86288161  4.75231114 #> V5           4.75791348  4.69033508 #> V6           4.63961136  4.47714823 #> V7          -4.83278909 -4.69375932 #> V8           2.01590285  1.99479801 #> V9           0.05065353  0.08332983 #> V10         -0.14142640 -0.14644338 #> V11         -4.84730705 -4.77336356 #> V12         -4.66596967 -4.56115266 #> V13         -4.81352148 -4.71580151 #> V14         -4.79079945 -4.65722652 #> V15         -4.94137922 -4.86577000 #> V16          .           .          #> V17          .           .          #> V18          .           .          #> V19          .           .          #> V20          .           ."},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation for a sparsegl object. — cv.sparsegl","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"Performs k-fold cross-validation sparsegl(). function largely similar glmnet::cv.glmnet().","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"","code":"cv.sparsegl(   x,   y,   group = NULL,   family = c(\"gaussian\", \"binomial\"),   lambda = NULL,   pred.loss = c(\"default\", \"mse\", \"deviance\", \"mae\", \"misclass\", \"auc\"),   nfolds = 10,   foldid = NULL,   weights = NULL,   offset = NULL,   ... )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"x Double. matrix predictors, dimension \\(n \\times p\\); row vector measurements column feature. Objects class Matrix::sparseMatrix supported. y Double/Integer/Factor. response variable. Quantitative family=\"gaussian\" exponential families. family=\"binomial\" either factor two levels vector integers taking 2 unique values. factor, last level alphabetical order target class. group Integer. vector consecutive integers describing grouping coefficients (see example ). family Character function. Specifies generalized linear model use. Valid options : \"gaussian\" - least squares loss (regression, default), \"binomial\" - logistic loss (classification) type, valid stats::family() object may passed. Note generally much slower estimate built-options passed strings. example, family = \"gaussian\" family = gaussian() produce results, first much faster. lambda user supplied lambda sequence. default, NULL results automatic computation based nlambda, smallest value lambda give null model (coefficient estimates equal zero), lambda.factor. Supplying value lambda overrides behaviour. likely better supply decreasing sequence lambda values single (small) value. supplied, user-defined lambda sequence automatically sorted decreasing order. pred.loss Loss use cross-validation error. Valid options : \"default\" deviance (mse regression deviance otherwise) \"mse\" mean square error \"deviance\" default (mse Gaussian regression, negative log-likelihood otherwise) \"mae\" mean absolute error, can apply family \"misclass\" classification , misclassification error. \"auc\" classification , area ROC curve nfolds Number folds - default 10. Although nfolds can large sample size (leave-one-CV), recommended large datasets. Smallest value allowable nfolds = 3. foldid optional vector values 1 nfolds identifying fold observation . supplied, nfolds can missing. weights Double vector. Optional observation weights. can used stats::family() object. Internally coerced sum number observations. offset Double vector. Optional offset (constant predictor without corresponding coefficient). can used stats::family() object. ... Additional arguments sparsegl().","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"object class cv.sparsegl() returned, list components describing cross-validation error. lambda values lambda used fits. cvm mean cross-validated error - vector length length(lambda). cvsd Estimate standard error cvm. cvupper Upper curve = cvm + cvsd. cvlower Lower curve = cvm - cvsd. name text string indicating type measure (plotting purposes). nnzero number non-zero coefficients lambda active_grps number active groups lambda sparsegl.fit fitted sparsegl() object full data. lambda.min optimal value lambda gives minimum cross validation error cvm. lambda.1se largest value lambda error within 1 standard error minimum. .min index lambda.min lambda sequence. .1se index lambda.1se lambda sequence. call function call.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"function runs sparsegl() nfolds + 1 times; first get lambda sequence, remainder compute fit folds omitted. average error standard error folds computed.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"Liang, X., Cohen, ., Sólon Heinsfeld, ., Pestilli, F., McDonald, D.J. 2024. sparsegl: R Package Estimating Sparse Group Lasso. Journal Statistical Software, Vol. 110(6): 1–23. doi:10.18637/jss.v110.i06 .","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) cv_fit <- cv.sparsegl(X, y, groups)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate information criteria. — estimate_risk","title":"Calculate information criteria. — estimate_risk","text":"function uses degrees freedom calculate various information criteria. function uses \"unknown variance\" version likelihood. implemented Gaussian regression. constant ignored (stats::extractAIC()).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate information criteria. — estimate_risk","text":"","code":"estimate_risk(object, x, type = c(\"AIC\", \"BIC\", \"GCV\"), approx_df = FALSE)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate information criteria. — estimate_risk","text":"object fitted object call sparsegl(). x Matrix. matrix predictors used estimate sparsegl object. May missing approx_df = TRUE. type one AIC, BIC, GCV. approx_df df component sparsegl object approximation (albeit fairly accurate one) actual degrees--freedom. However, exact value requires inverting portion X'X. computation may take time (default computes exact df).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate information criteria. — estimate_risk","text":"data.frame many rows object$lambda. contains columns lambda, df, requested risk types.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate information criteria. — estimate_risk","text":"Liang, X., Cohen, ., Sólon Heinsfeld, ., Pestilli, F., McDonald, D.J. 2024. sparsegl: R Package Estimating Sparse Group Lasso. Journal Statistical Software, Vol. 110(6): 1–23. doi:10.18637/jss.v110.i06 . Vaiter S, Deledalle C, Peyré G, Fadili J, Dossal C. (2012). Degrees Freedom Group Lasso General Design. https://arxiv.org/abs/1212.6478.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate information criteria. — estimate_risk","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) estimate_risk(fit1, type = \"AIC\", approx_df = TRUE) #>           lambda        df        AIC #> s0  5.900845e-01  0.000000 5.62197152 #> s1  5.376630e-01  5.278870 5.72025002 #> s2  4.898985e-01  6.970448 5.67566864 #> s3  4.463773e-01  7.647520 5.61863516 #> s4  4.067223e-01 14.736619 5.63899114 #> s5  3.705903e-01 15.899430 5.51804310 #> s6  3.376680e-01 16.473363 5.39067065 #> s7  3.076705e-01 16.821002 5.26475291 #> s8  2.803379e-01 22.518053 5.20267933 #> s9  2.554335e-01 23.241976 5.03821110 #> s10 2.327415e-01 23.647648 4.86723635 #> s11 2.120654e-01 23.913533 4.69337809 #> s12 1.932261e-01 24.103329 4.51796193 #> s13 1.760604e-01 24.246227 4.34163322 #> s14 1.604197e-01 24.357796 4.16477629 #> s15 1.461684e-01 24.447226 3.98766139 #> s16 1.331832e-01 24.520351 3.81050724 #> s17 1.213516e-01 24.581083 3.63351226 #> s18 1.105711e-01 24.632157 3.45687229 #> s19 1.007482e-01 24.675551 3.28079221 #> s20 9.179804e-02 24.712736 3.10549439 #> s21 8.364295e-02 24.744832 2.93122566 #> s22 7.621234e-02 24.772704 2.75826329 #> s23 6.944185e-02 24.797038 2.58692033 #> s24 6.327282e-02 24.818381 2.41755033 #> s25 5.765184e-02 24.837175 2.25055108 #> s26 5.253021e-02 24.853783 2.08636708 #> s27 4.786357e-02 26.851883 1.96513115 #> s28 4.361150e-02 26.866683 1.80807789 #> s29 3.973718e-02 26.879860 1.65542955 #> s30 3.620704e-02 26.891617 1.50789227 #> s31 3.299050e-02 26.902130 1.36589158 #> s32 3.005972e-02 26.911547 1.23014565 #> s33 2.738930e-02 26.919997 1.10125019 #> s34 2.495611e-02 26.927588 0.97974813 #> s35 2.273907e-02 26.934419 0.86610281 #> s36 2.071900e-02 26.940571 0.76067201 #> s37 1.887838e-02 26.946119 0.66368630 #> s38 1.720128e-02 26.951127 0.57523447 #> s39 1.567316e-02 26.955650 0.49539451 #> s40 1.428080e-02 26.959740 0.42368138 #> s41 1.301213e-02 26.963440 0.35991011 #> s42 1.185617e-02 26.966790 0.30364463 #> s43 1.080290e-02 26.969825 0.25436430 #> s44 9.843202e-03 26.972575 0.21149356 #> s45 8.968759e-03 26.975069 0.17442864 #> s46 8.172000e-03 26.977331 0.14256134 #> s47 7.446022e-03 26.979384 0.11529854 #> s48 6.784538e-03 26.981248 0.09216864 #> s49 6.181818e-03 26.982941 0.07245370 #> s50 5.632642e-03 26.984479 0.05577853 #> s51 5.132254e-03 26.985876 0.04171683 #> s52 4.676319e-03 34.048135 0.16717956 #> s53 4.260887e-03 34.843467 0.16910750 #> s54 3.882362e-03 35.200509 0.16437620 #> s55 3.537464e-03 35.402987 0.15842000 #> s56 3.223205e-03 35.532897 0.15260521 #> s57 2.936864e-03 35.622969 0.14734603 #> s58 2.675961e-03 35.688834 0.14274704 #> s59 2.438236e-03 35.738898 0.13879760 #> s60 2.221630e-03 35.778083 0.13544334 #> s61 2.024267e-03 35.809298 0.13265062 #> s62 1.844436e-03 35.834922 0.13027732 #> s63 1.680582e-03 35.856144 0.12829319 #> s64 1.531284e-03 35.873931 0.12664168 #> s65 1.395249e-03 35.888993 0.12527118 #> s66 1.271298e-03 35.901861 0.12413684 #> s67 1.158360e-03 35.912936 0.12320024 #> s68 1.055454e-03 35.922530 0.12242870 #> s69 9.616907e-04 35.930889 0.12179462 #> s70 8.762567e-04 35.938205 0.12127473 #> s71 7.984125e-04 33.957909 0.08113024 #> s72 7.274837e-04 33.962166 0.08078818 #> s73 6.628561e-04 33.965978 0.08048188 #> s74 6.039698e-04 35.959710 0.12003410 #> s75 5.503148e-04 35.963696 0.11984380 #> s76 5.014263e-04 35.967253 0.11968965 #> s77 4.568810e-04 35.970433 0.11956579 #> s78 4.162929e-04 35.973281 0.11946692 #> s79 3.793106e-04 35.975835 0.11938853 #> s80 3.456137e-04 35.978093 0.11935164 #> s81 3.149103e-04 35.980188 0.11928224 #> s82 2.869346e-04 35.982026 0.11926050 #> s83 2.614441e-04 35.983699 0.11923444 #> s84 2.382181e-04 35.985213 0.11921207 #> s85 2.170555e-04 35.986583 0.11919456 #> s86 1.977729e-04 35.987822 0.11918155 #> s87 1.802033e-04 35.988943 0.11917235 #> s88 1.641945e-04 35.989958 0.11916628 #> s89 1.496079e-04 35.990877 0.11916270 #> s90 1.363172e-04 35.991709 0.11916108 #> s91 1.242071e-04 35.992464 0.11916099 #> s92 1.131729e-04 35.993149 0.11916206 #> s93 1.031189e-04 35.993770 0.11916399 #> s94 9.395814e-05 35.994334 0.11916656 #> s95 8.561115e-05 35.994846 0.11916956 #> s96 7.800570e-05 35.995311 0.11917285 #> s97 7.107588e-05 35.995733 0.11917631 #> s98 6.476170e-05 35.996117 0.11917985 #> s99 5.900845e-05 35.996466 0.11918338"},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate common norms — zero_norm","title":"Calculate common norms — zero_norm","text":"Calculate different norms vectors without grouping structures.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate common norms — zero_norm","text":"","code":"zero_norm(x)  one_norm(x)  two_norm(x)  grouped_zero_norm(x, gr)  grouped_one_norm(x, gr)  grouped_two_norm(x, gr)  grouped_sp_norm(x, gr, asparse)  gr_one_norm(x, gr)  gr_two_norm(x, gr)  sp_group_norm(x, gr, asparse = 0.05)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate common norms — zero_norm","text":"x numeric vector. gr integer (factor) vector length x. asparse Scalar. weight put l1 norm calculating group norm.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate common norms — zero_norm","text":"numeric scalar vector","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Calculate common norms — zero_norm","text":"zero_norm(): l0-norm (number nonzero entries). one_norm(): l1-norm (Absolute-value norm). two_norm(): l2-norm (Euclidean norm). grouped_zero_norm(): vector group-wise l0-norms. grouped_one_norm(): vector group-wise l1-norms. grouped_two_norm(): vector group-wise l2-norms. grouped_sp_norm(): vector length unique(gr) consisting asparse convex combination l1 l2-norm group. gr_one_norm(): l1-norm norm vector (scalar). gr_two_norm(): sum group-wise l2-norms vector (scalar). sp_group_norm(): sum asparse convex combination group l1 l2-norms vectors (scalar).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate common norms — zero_norm","text":"","code":"x <- c(rep(-1, 5), rep(0, 5), rep(1, 5)) gr <- c(rep(1, 5), rep(2, 5), rep(3, 5)) asparse <- 0.05 grouped_sp_norm(x, gr, asparse) #> [1] 2.374265 0.000000 2.374265"},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":null,"dir":"Reference","previous_headings":"","what":"Create starting values for iterative reweighted least squares — make_irls_warmup","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"function may used create potentially valid starting values calling sparsegl() stats::family() object. typically necessary call function (used internally create ), cases, especially custom generalized linear models, may improve performance.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"","code":"make_irls_warmup(nobs, nvars, b0 = 0, beta = double(nvars), r = double(nobs))"},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"nobs Number observations response (rows x). nvars Number columns x b0 Scalar. Initial value intercept. beta Vector. Initial values coefficients. Must length nvars (scalar). r Vector. Initial values deviance residuals. Must length nobs (scalar).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"List class irlsspgl_warmup","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"Occasionally, irls fitting routine may fail admonition create valid starting values.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"Plots average cross-validation error upper lower 1 standard error bars. Dashed lines indicate lambda optimizes CV error 1 standard error lambda.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"","code":"# S3 method for class 'cv.sparsegl' plot(x, log_axis = c(\"xy\", \"x\", \"y\", \"none\"), sign.lambda = 1, ...)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"x Fitted \"cv.sparsegl\" object, produced cv.sparsegl(). log_axis Apply log scaling requested axes. sign.lambda Either plot log(lambda) (default) reverse sign.lambda < 0. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"ggplot2::ggplot() plot produced. Additional user modifications may added desired.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) cv_fit <- cv.sparsegl(X, y, groups) plot(cv_fit)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot solution paths from a sparsegl object. — plot.sparsegl","title":"Plot solution paths from a sparsegl object. — plot.sparsegl","text":"Produces coefficient profile plot fitted sparsegl() object. result ggplot2::ggplot(). Additional user modifications can added desired.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot solution paths from a sparsegl object. — plot.sparsegl","text":"","code":"# S3 method for class 'sparsegl' plot(   x,   y_axis = c(\"coef\", \"group\"),   x_axis = c(\"lambda\", \"penalty\"),   add_legend = n_legend_values < 20,   ... )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot solution paths from a sparsegl object. — plot.sparsegl","text":"x Fitted \"sparsegl\" object, produced sparsegl(). y_axis Variable y_axis. Either coefficients (default) group norm. x_axis Variable x-axis. Either (log)-lambda sequence (default) value penalty. second case, penalty scaled maximum along path. add_legend Show legend. Often, many groups/predictors, can become overwhelming. default produces legend number groups/predictors less 20. ... used.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot solution paths from a sparsegl object. — plot.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) plot(fit1, y_axis = \"coef\", x_axis = \"penalty\")"},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"function makes predictions cross-validated cv.sparsegl() object, using stored sparsegl.fit object, value chosen lambda.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"","code":"# S3 method for class 'cv.sparsegl' predict(   object,   newx,   s = c(\"lambda.1se\", \"lambda.min\"),   type = c(\"link\", \"response\", \"coefficients\", \"nonzero\", \"class\"),   ... )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"object Fitted cv.sparsegl() object. newx Matrix new values x predictions made. Must matrix. argument mandatory. s Value(s) penalty parameter lambda coefficients desired. Default single value s = \"lambda.1se\" stored CV object (corresponding largest value lambda CV error estimate within 1 standard error minimum). Alternatively s = \"lambda.min\" can used (corresponding minimum cross validation error estimate). s numeric, taken value(s) lambda used. type Type prediction required. Type \"link\" gives linear predictors \"binomial\"; \"gaussian\" models gives fitted values. Type \"response\" gives predictions scale response (example, fitted probabilities \"binomial\"); \"gaussian\" type \"response\" equivalent type \"link\". Type \"coefficients\" computes coefficients requested values s. Type \"class\" applies \"binomial\" models, produces class label corresponding maximum probability. Type \"nonzero\" returns list indices nonzero coefficients value s. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"matrix vector predicted values.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) cv_fit <- cv.sparsegl(X, y, groups) predict(cv_fit, newx = X[50:60, ], s = \"lambda.min\") #>               s1 #>  [1,] -10.072840 #>  [2,]  -6.389955 #>  [3,]   6.990590 #>  [4,] -30.943405 #>  [5,]   1.602502 #>  [6,]   5.735981 #>  [7,]  -5.801251 #>  [8,]  22.980565 #>  [9,] -31.601579 #> [10,]   3.703521 #> [11,]  35.895824"},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Make predictions from a sparsegl object. — predict.sparsegl","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"Similar predict methods, function produces fitted values class labels fitted sparsegl object.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"","code":"# S3 method for class 'sparsegl' predict(   object,   newx,   s = NULL,   type = c(\"link\", \"response\", \"coefficients\", \"nonzero\", \"class\"),   ... )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"object Fitted sparsegl() model object. newx Matrix new values x predictions made. Must matrix. argument mandatory. s Value(s) penalty parameter lambda predictions required. Default entire sequence used create model. type Type prediction required. Type \"link\" gives linear predictors \"binomial\"; \"gaussian\" models gives fitted values. Type \"response\" gives predictions scale response (example, fitted probabilities \"binomial\"); \"gaussian\" type \"response\" equivalent type \"link\". Type \"coefficients\" computes coefficients requested values s. Type \"class\" applies \"binomial\" models, produces class label corresponding maximum probability. Type \"nonzero\" returns list indices nonzero coefficients value s. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"object returned depends type.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"s new vector lambda values predictions requested. s lambda sequence used fitting model, coef function use linear interpolation make predictions. new values interpolated using fraction coefficients left right lambda indices.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) predict(fit1, newx = X[10, ], s = fit1$lambda[3:5]) #>             s1        s2         s3 #> [1,] -1.325783 -1.009143 -0.8451558"},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl-package.html","id":null,"dir":"Reference","previous_headings":"","what":"sparsegl: Sparse Group Lasso — sparsegl-package","title":"sparsegl: Sparse Group Lasso — sparsegl-package","text":"Efficient implementation sparse group lasso optional bound constraints coefficients; see Liang, et al., (2024) doi:10.18637/jss.v110.i06 . supports use sparse design matrix well returning coefficient estimates sparse matrix. Furthermore, correctly calculates degrees freedom allow information criteria rather cross-validation large data. Finally, interface compiled code avoids unnecessary copies allows use long integers.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"sparsegl: Sparse Group Lasso — sparsegl-package","text":"Liang, X., Cohen, ., Sólon Heinsfeld, ., Pestilli, F., McDonald, D.J. 2024. \"sparsegl: R Package Estimating Sparse Group Lasso.\" Journal Statistical Software, 110(6): 1–23. doi:10.18637/jss.v110.i06.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"sparsegl: Sparse Group Lasso — sparsegl-package","text":"Maintainer: Daniel J. McDonald daniel@stat.ubc.ca [copyright holder] Authors: Xiaoxuan Liang xiaoxuan.liang@stat.ubc.ca Anibal Solón Heinsfeld anibalsolon@gmail.com Aaron Cohen cohenaa@indiana.edu contributors: Yi Yang yi.yang6@mcgill.ca [contributor] Hui Zou [contributor] Jerome Friedman [contributor] Trevor Hastie [contributor] Rob Tibshirani [contributor] Balasubramanian Narasimhan [contributor] Kenneth Tay [contributor] Noah Simon [contributor] Junyang Qian [contributor] James Yang [contributor]","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Regularization paths for sparse group-lasso models — sparsegl","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"Fits regularization paths sparse group-lasso penalized learning problems sequence regularization parameters lambda. Note objective function least squares $$RSS/(2n) + \\lambda penalty$$ Users can also tweak penalty choosing different penalty factor.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"","code":"sparsegl(   x,   y,   group = NULL,   family = c(\"gaussian\", \"binomial\"),   nlambda = 100,   lambda.factor = ifelse(nobs < nvars, 0.01, 1e-04),   lambda = NULL,   pf_group = sqrt(bs),   pf_sparse = rep(1, nvars),   intercept = TRUE,   asparse = 0.05,   standardize = TRUE,   lower_bnd = -Inf,   upper_bnd = Inf,   weights = NULL,   offset = NULL,   warm = NULL,   trace_it = 0,   dfmax = as.integer(max(group)) + 1L,   pmax = min(dfmax * 1.2, as.integer(max(group))),   eps = 1e-08,   maxit = 3e+06 )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"x Double. matrix predictors, dimension \\(n \\times p\\); row vector measurements column feature. Objects class Matrix::sparseMatrix supported. y Double/Integer/Factor. response variable. Quantitative family=\"gaussian\" exponential families. family=\"binomial\" either factor two levels vector integers taking 2 unique values. factor, last level alphabetical order target class. group Integer. vector consecutive integers describing grouping coefficients (see example ). family Character function. Specifies generalized linear model use. Valid options : \"gaussian\" - least squares loss (regression, default), \"binomial\" - logistic loss (classification) type, valid stats::family() object may passed. Note generally much slower estimate built-options passed strings. example, family = \"gaussian\" family = gaussian() produce results, first much faster. nlambda number lambda values - default 100. lambda.factor multiplicative factor minimal lambda lambda sequence, min(lambda) = lambda.factor * max(lambda). max(lambda) smallest value lambda coefficients zero. default depends relationship \\(n\\) (number rows matrix predictors) \\(p\\) (number predictors). \\(n \\geq p\\), default 0.0001.  \\(n < p\\), default 0.01. small value lambda.factor lead saturated fit. argument effect user-defined lambda sequence. lambda user supplied lambda sequence. default, NULL results automatic computation based nlambda, smallest value lambda give null model (coefficient estimates equal zero), lambda.factor. Supplying value lambda overrides behaviour. likely better supply decreasing sequence lambda values single (small) value. supplied, user-defined lambda sequence automatically sorted decreasing order. pf_group Penalty factor groups, vector length total number groups. Separate penalty weights can applied group \\(\\beta\\)s allow differential shrinkage. Can 0 groups, implies shrinkage, results group always included model (depending pf_sparse). Default value entry square-root corresponding size group. default typical, penalties rescaled. pf_sparse Penalty factor l1-norm, vector length total number columns x. value corresponds one predictor Can 0 predictors, implies predictor receive group penalty. Note internally rescaled sum number predictors. intercept Whether include intercept model. Default TRUE. asparse relative weight put \\(\\ell_1\\)-norm sparse group lasso. Default 0.05 (resulting 0.95 \\(\\ell_2\\)-norm). standardize Logical flag variable standardization (scaling) prior fitting model. Default TRUE. lower_bnd Lower bound coefficient values, vector length 1 length number groups. Must non-positive numbers . Default value entry -Inf. upper_bnd Upper coefficient values, vector length 1 length number groups. Must non-negative numbers . Default value entry Inf. weights Double vector. Optional observation weights. can used stats::family() object. Internally coerced sum number observations. offset Double vector. Optional offset (constant predictor without corresponding coefficient). can used stats::family() object. warm List created make_irls_warmup(). can used stats::family() object, typically necessary even . trace_it Scalar integer. Larger values print output irls loop. Typical values 0 (printing), 1 (printing progress bar), 2 (detailed printing). can used stats::family() object. dfmax Limit maximum number groups model. Default limit. pmax Limit maximum number groups ever nonzero. example group enters model, matter many times exits re-enters model path, counted . eps Convergence termination tolerance. Defaults value 1e-8. maxit Maximum number outer-loop iterations allowed fixed lambda value. Default 3e8. models converge, consider increasing maxit.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"object S3 class \"sparsegl\". Among list components: call call produced object. b0 Intercept sequence length length(lambda). beta p x length(lambda) sparse matrix coefficients. df number features nonzero coefficients value lambda. dim Dimension coefficient matrix. lambda actual sequence lambda values used. npasses Total number iterations summed lambda values. jerr Error flag, warnings errors, 0 error. group vector consecutive integers describing grouping coefficients. nobs number observations used estimate model. sparsegl() called stats::family() method, may also contain information deviance family used fitting.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"Liang, X., Cohen, ., Sólon Heinsfeld, ., Pestilli, F., McDonald, D.J. 2024. sparsegl: R Package Estimating Sparse Group Lasso. Journal Statistical Software, Vol. 110(6): 1–23. doi:10.18637/jss.v110.i06 .","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit <- sparsegl(X, y, group = groups)  yp <- rpois(n, abs(X %*% beta_star)) fit_pois <- sparsegl(X, yp, group = groups, family = poisson())"},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":null,"dir":"Reference","previous_headings":"","what":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"dataset containing measurement \"trust\" experts along metrics collected Delphi Group Carnegie Mellon University U.S. COVID-19 Trends Impact Survey, partnership Facebook. particular dataset created one public contingency tables, specifically, breakdown state, age, gender, race/ethnicity published 05 February 2022.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"","code":"trust_experts"},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"data.frame 9759 rows 8 columns trust_experts Real-valued. average pct_trust_covid_info_* * doctors, experts, cdc, govt_health. period Factor. Start date data collection period. 13 monthly periods region Factor. State abbreviation. age Factor. Self-reported age bucket. gender Factor. Self-reported gender. raceethnicity Factor. Self-reported race ethnicity. cli Real-valued. wcli indicator measuring percent circulating Covid-like illness particular region. See Delphi Epidata API complete description. hh_cmnty_cli Real-valued. whh_cmnty_cli indicator measuring percent people reporting illness local community household.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"U.S. COVID-19 Trends Impact Survey. paper describing survey: Joshua . Salomon, Alex Reinhart, Alyssa Bilinski, Eu Jing Chua, Wichada La Motte-Kerr, Minttu M. Rönn, Marissa Reitsma, Katherine Ann Morris, Sarah LaRocca, Tamar Farag, Frauke Kreuter, Roni Rosenfeld, Ryan J. Tibshirani (2021). \"US COVID-19 Trends Impact Survey: Continuous real-time measurement COVID-19 symptoms, risks, protective behaviors, testing, vaccination\", Proceedings National Academy Sciences 118 (51) e2111454118. doi:10.1073/pnas.2111454118 . Public Delphi US CTIS Documentation","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"","code":"if (FALSE) { # \\dontrun{ library(splines) library(dplyr) df <- 10  trust_experts <- mutate(   trust_experts,   across(     where(is.factor),     ~ rlang::set_attrs(.x, \"contrasts\", contr.sum(nlevels(.x), FALSE, TRUE))   ))  x <- Matrix::sparse.model.matrix(   ~ 0 + region + age + gender + raceethnicity + period +     bs(cli, df = df) + bs(hh_cmnty_cli, df = df),   data = trust_experts, drop.unused.levels = TRUE )  gr <- sapply(trust_experts, function(x) ifelse(is.factor(x), nlevels(x), NA)) gr <- rep(seq(ncol(trust_experts) - 1), times = c(gr[!is.na(gr)], df, df)) fit <- cv.sparsegl(x, trust_experts$trust_experts, gr) } # }"},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-development-version","dir":"Changelog","previous_headings":"","what":"sparsegl (development version)","title":"sparsegl (development version)","text":"Force weights sum nobs IRWLS cases. Remove magrittr imports Add auc option CV binomial","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-111","dir":"Changelog","previous_headings":"","what":"sparsegl 1.1.1","title":"sparsegl 1.1.1","text":"Add CITATION links JSS article","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-110","dir":"Changelog","previous_headings":"","what":"sparsegl 1.1.0","title":"sparsegl 1.1.0","text":"Address CRAN issues FORTRAN builds GCC 14.1","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-102","dir":"Changelog","previous_headings":"","what":"sparsegl 1.0.2","title":"sparsegl 1.0.2","text":"Corrects bug / adds support weights offset cv minor tweaks error warning messages","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-101","dir":"Changelog","previous_headings":"","what":"sparsegl 1.0.1","title":"sparsegl 1.0.1","text":"Remove unnecessary attributes included data","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-100","dir":"Changelog","previous_headings":"","what":"sparsegl 1.0.0","title":"sparsegl 1.0.0","text":"Improved documentation Added functionality implement arbitrary stats::family() fitting. Enhanced (corrected) S3 interface predict coef methods.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-050","dir":"Changelog","previous_headings":"","what":"sparsegl 0.5.0","title":"sparsegl 0.5.0","text":"Minor internal updates pass additional CRAN checks Refactor documentation Intercept calculation internal Fortran source cases.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-040","dir":"Changelog","previous_headings":"","what":"sparsegl 0.4.0","title":"sparsegl 0.4.0","text":"Add option weight individual coefficients l1 penalty. Remove coercions type (<matrix>, \"dgCMatrix\"). deprecated Matrix>=1.4-2 Warn CRAN checks. Compute MSE internally Fortran family = \"Gaussian\". Avoids creation potentially large matrix predicted values purposes risk estimation. Revise estimate_risk() signature. Now x optional y required.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-030","dir":"Changelog","previous_headings":"","what":"sparsegl 0.3.0","title":"sparsegl 0.3.0","text":"Initial version CRAN.","code":""}]
