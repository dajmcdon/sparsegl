[{"path":"https://dajmcdon.github.io/sparsegl/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 2, June 1991Copyright © 1989, 1991 Free Software Foundation, Inc.,51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"licenses software designed take away freedom share change . contrast, GNU General Public License intended guarantee freedom share change free software–make sure software free users. General Public License applies Free Software Foundation’s software program whose authors commit using . (Free Software Foundation software covered GNU Lesser General Public License instead.) can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge service wish), receive source code can get want , can change software use pieces new free programs; know can things. protect rights, need make restrictions forbid anyone deny rights ask surrender rights. restrictions translate certain responsibilities distribute copies software, modify . example, distribute copies program, whether gratis fee, must give recipients rights . must make sure , , receive can get source code. must show terms know rights. protect rights two steps: (1) copyright software, (2) offer license gives legal permission copy, distribute /modify software. Also, author’s protection , want make certain everyone understands warranty free software. software modified someone else passed , want recipients know original, problems introduced others reflect original authors’ reputations. Finally, free program threatened constantly software patents. wish avoid danger redistributors free program individually obtain patent licenses, effect making program proprietary. prevent , made clear patent must licensed everyone’s free use licensed . precise terms conditions copying, distribution modification follow.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/LICENSE.html","id":"terms-and-conditions-for-copying-distribution-and-modification","dir":"","previous_headings":"","what":"TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION","title":"GNU General Public License","text":"0. License applies program work contains notice placed copyright holder saying may distributed terms General Public License. “Program”, , refers program work, “work based Program” means either Program derivative work copyright law: say, work containing Program portion , either verbatim modifications /translated another language. (Hereinafter, translation included without limitation term “modification”.) licensee addressed “”. Activities copying, distribution modification covered License; outside scope. act running Program restricted, output Program covered contents constitute work based Program (independent made running Program). Whether true depends Program . 1. may copy distribute verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice disclaimer warranty; keep intact notices refer License absence warranty; give recipients Program copy License along Program. may charge fee physical act transferring copy, may option offer warranty protection exchange fee. 2. may modify copy copies Program portion , thus forming work based Program, copy distribute modifications work terms Section 1 , provided also meet conditions: ) must cause modified files carry prominent notices stating changed files date change. b) must cause work distribute publish, whole part contains derived Program part thereof, licensed whole charge third parties terms License. c) modified program normally reads commands interactively run, must cause , started running interactive use ordinary way, print display announcement including appropriate copyright notice notice warranty (else, saying provide warranty) users may redistribute program conditions, telling user view copy License. (Exception: Program interactive normally print announcement, work based Program required print announcement.) requirements apply modified work whole. identifiable sections work derived Program, can reasonably considered independent separate works , License, terms, apply sections distribute separate works. distribute sections part whole work based Program, distribution whole must terms License, whose permissions licensees extend entire whole, thus every part regardless wrote . Thus, intent section claim rights contest rights work written entirely ; rather, intent exercise right control distribution derivative collective works based Program. addition, mere aggregation another work based Program Program (work based Program) volume storage distribution medium bring work scope License. 3. may copy distribute Program (work based , Section 2) object code executable form terms Sections 1 2 provided also one following: ) Accompany complete corresponding machine-readable source code, must distributed terms Sections 1 2 medium customarily used software interchange; , b) Accompany written offer, valid least three years, give third party, charge cost physically performing source distribution, complete machine-readable copy corresponding source code, distributed terms Sections 1 2 medium customarily used software interchange; , c) Accompany information received offer distribute corresponding source code. (alternative allowed noncommercial distribution received program object code executable form offer, accord Subsection b .) source code work means preferred form work making modifications . executable work, complete source code means source code modules contains, plus associated interface definition files, plus scripts used control compilation installation executable. However, special exception, source code distributed need include anything normally distributed (either source binary form) major components (compiler, kernel, ) operating system executable runs, unless component accompanies executable. distribution executable object code made offering access copy designated place, offering equivalent access copy source code place counts distribution source code, even though third parties compelled copy source along object code. 4. may copy, modify, sublicense, distribute Program except expressly provided License. attempt otherwise copy, modify, sublicense distribute Program void, automatically terminate rights License. However, parties received copies, rights, License licenses terminated long parties remain full compliance. 5. required accept License, since signed . However, nothing else grants permission modify distribute Program derivative works. actions prohibited law accept License. Therefore, modifying distributing Program (work based Program), indicate acceptance License , terms conditions copying, distributing modifying Program works based . 6. time redistribute Program (work based Program), recipient automatically receives license original licensor copy, distribute modify Program subject terms conditions. may impose restrictions recipients’ exercise rights granted herein. responsible enforcing compliance third parties License. 7. , consequence court judgment allegation patent infringement reason (limited patent issues), conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. distribute satisfy simultaneously obligations License pertinent obligations, consequence may distribute Program . example, patent license permit royalty-free redistribution Program receive copies directly indirectly , way satisfy License refrain entirely distribution Program. portion section held invalid unenforceable particular circumstance, balance section intended apply section whole intended apply circumstances. purpose section induce infringe patents property right claims contest validity claims; section sole purpose protecting integrity free software distribution system, implemented public license practices. Many people made generous contributions wide range software distributed system reliance consistent application system; author/donor decide willing distribute software system licensee impose choice. section intended make thoroughly clear believed consequence rest License. 8. distribution /use Program restricted certain countries either patents copyrighted interfaces, original copyright holder places Program License may add explicit geographical distribution limitation excluding countries, distribution permitted among countries thus excluded. case, License incorporates limitation written body License. 9. Free Software Foundation may publish revised /new versions General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies version number License applies “later version”, option following terms conditions either version later version published Free Software Foundation. Program specify version number License, may choose version ever published Free Software Foundation. 10. wish incorporate parts Program free programs whose distribution conditions different, write author ask permission. software copyrighted Free Software Foundation, write Free Software Foundation; sometimes make exceptions . decision guided two goals preserving free status derivatives free software promoting sharing reuse software generally.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/LICENSE.html","id":"no-warranty","dir":"","previous_headings":"","what":"NO WARRANTY","title":"GNU General Public License","text":"11. PROGRAM LICENSED FREE CHARGE, WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION. 12. EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MAY MODIFY /REDISTRIBUTE PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES. END TERMS CONDITIONS","code":""},{"path":"https://dajmcdon.github.io/sparsegl/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively convey exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program interactive, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, commands use may called something show w show c; even mouse-clicks menu items–whatever suits program. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. sample; alter names: General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. Gnomovision version 69, Copyright (C) year name of author Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details. Yoyodyne, Inc., hereby disclaims all copyright interest in the program `Gnomovision' (which makes passes at compilers) written by James Hacker.  <signature of Ty Coon>, 1 April 1989 Ty Coon, President of Vice"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"installing","dir":"Articles","previous_headings":"","what":"Installing","title":"Getting started with sparsegl","text":"can install released version sparsegl CRAN : can install development version Github : Vignettes included package default. want include vignettes, use modified command: getting-started vignette, first, randomly generate X, input matrix predictors dimension \\(n\\times p\\). create y, real-valued vector, use either Linear Regression model: \\(y = X\\beta^* + \\epsilon\\). Logistic regression model: \\(y = (y_1, y_2, \\cdots, y_n)\\), \\(y_i \\sim \\text{Bernoulli}\\left(\\frac{1}{1 + \\exp(-x_i^\\top \\beta^*)}\\right)\\), \\(= 1, 2, \\cdots, n.\\) coefficient vector \\(\\beta^*\\) specified , white noise \\(\\epsilon\\) follows standard normal distribution. sparse group-lasso problem formulated sum mean squared error (linear regression) logistic loss (logistic regression) convex combination \\(\\ell_1\\) lasso penalty \\(\\ell_2\\) group lasso penalty: Linear regression: \\[ \\min_{\\beta\\\\mathbb{R}^p}\\left(\\frac{1}{2n} \\rVert y - \\sum_g X^{(g)}\\beta^{(g)}\\rVert_2^2 + (1-\\alpha)\\lambda\\sum_g \\sqrt{|g|}\\rVert\\beta^{(g)}\\rVert_2 + \\alpha\\lambda\\rVert\\beta\\rVert_1 \\right) \\qquad (*). \\] Logistic regression: \\[ \\min_{\\beta\\\\mathbb{R}^p}\\left(\\frac{1}{2n}\\sum_{=1}^n \\log\\left(1 + \\exp\\left(-y_ix_i^\\top\\beta\\right)\\right) + (1-\\alpha)\\lambda\\sum_g \\sqrt{|g|}\\rVert\\beta^{(g)}\\rVert_2 + \\alpha\\lambda\\rVert\\beta\\rVert_1 \\right) \\qquad (**). \\] \\(X^{(g)}\\) submatrix \\(X\\) columns corresponding features group \\(g\\). \\(\\beta^{(g)}\\) corresponding coefficients features group \\(g\\). \\(|g|\\) number predictors group \\(g\\). \\(\\alpha\\) adjusts weight lasso penalty group-lasso penalty. \\(\\lambda\\) fine-tunes size penalty imposed model control number nonzero coefficients.","code":"install.packages(\"sparsegl\") # install.packages(\"remotes\") remotes::install_github(\"dajmcdon/sparsegl\") remotes::install_github(   \"dajmcdon/sparsegl\",    build_vignettes = TRUE, dependencies = TRUE ) library(sparsegl) set.seed(1010) n <- 100 p <- 200 X <- matrix(data = rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5),                 c(2, -3, 8, 0, 0), rep(0, (p - 20))) groups <- rep(1:(p / 5), each = 5)  # Linear regression model eps <- rnorm(n, mean = 0, sd = 1) y <- X %*% beta_star + eps  # Logistic regression model pr <- 1 / (1 + exp(-X %*% beta_star)) y_binary <- rbinom(n, 1, pr)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"sparsegl","dir":"Articles","previous_headings":"","what":"sparsegl()","title":"Getting started with sparsegl","text":"Given input matrix X, response vector y, sparse group-lasso regularized linear model estimated sequence penalty parameter values. penalty composed lasso penalty group lasso penalty. main arguments users might supply : group: vector consecutive integers length p indicating grouping features. default, group contains one feature without initialization. family: character string specifying likelihood use, either linear regression \"gaussian\" logistic regression loss \"binomial\". Default \"gaussian\". exponential families required, stats::family() object may used (e.g. poisson()). case, arguments providing observation weights offset terms allowed well. pf_group: Separate penalty weights can applied group \\(\\beta_g\\) allow differential shrinkage. Can 0 groups, implies shrinkage. default value entry square-root corresponding size group. pf_sparse: Penalty factor \\(\\ell_1\\)-norm, vector length total number columns x. value corresponds one predictor Can 0 predictors, implies predictor receive group penalty. asparse: changes weight lasso penalty, referring \\(\\alpha\\) \\((*)\\) \\((**)\\) : asparse = \\(1\\) gives lasso penalty . asparse = \\(0\\) gives group lasso penalty . default value asparse \\(0.05\\). lower_bnd: lower bound coefficient values, vector length 1 number groups including non-positive numbers . Default value entry -\\(\\infty\\). upper_bnd: upper bound coefficient values, vector length 1 number groups including non-negative numbers . Default value entry \\(\\infty\\).","code":"fit1 <- sparsegl(X, y, group = groups)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"plotting-sparsegl-objects","dir":"Articles","previous_headings":"sparsegl()","what":"Plotting sparsegl objects","title":"Getting started with sparsegl","text":"function displays nonzero coefficient curves penalty parameter lambda values regularization path fitted sparsegl object. arguments function : y_axis: can set either \"coef\" \"group\". Default \"coef\". x_axis: can set either \"lambda\" \"penalty\". Default \"lambda\". elaborate arguments: plot y_axis = \"group\" shows group norms log-lambda scaled group norm vector. group norm defined : \\[ \\alpha\\rVert\\beta^{(g)}\\rVert_1 + (1 - \\alpha)\\sum_g\\rVert\\beta^{(g)}\\rVert_2 \\] Curves plotted color corresponding features group. Note number curves shown plots may less actual number groups since groups containing nonzero features least one \\(\\lambda\\) sequence included. plot y_axis = \"coef\" shows estimated coefficients lambda scaled group norm. , features nonzero estimates least one \\(\\lambda\\) value sequence displayed. plot x_axis = \"lambda\" indicates x_axis displays \\(\\log(\\lambda)\\). plot x_axis = \"penalty\" indicates x_axis displays scaled group norm vector. element vector defined : \\[ \\frac{\\alpha\\rVert \\beta\\rVert_1 + (1-\\alpha)\\sum_g\\rVert \\beta^{(g)}\\rVert_2}{\\max_\\beta\\left(\\alpha \\rVert \\beta\\rVert_1 + (1-\\alpha)\\sum_g\\rVert \\beta^{(g)}\\rVert_2\\right)} \\]","code":"plot(fit1, y_axis = \"group\", x_axis = \"lambda\") plot(fit1, y_axis = \"coef\", x_axis = \"penalty\", add_legend = FALSE)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"cv-sparsegl","dir":"Articles","previous_headings":"","what":"cv.sparsegl()","title":"Getting started with sparsegl","text":"function performs k-fold cross-validation (cv). takes arguments X, y, group, specified , additional argument pred.loss error measure. Options \"default\", \"mse\", \"deviance\", \"mae\", \"misclass\". family = \"gaussian\", \"default\" equivalent \"mse\" \"deviance\". general, \"deviance\" give negative log-likelihood. option \"misclass\" available family = \"binomial\".","code":"fit_l1 <- cv.sparsegl(X, y, group = groups, pred.loss = \"mae\") plot(fit_l1)"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"methods","dir":"Articles","previous_headings":"cv.sparsegl()","what":"Methods","title":"Getting started with sparsegl","text":"number S3 methods provided sparsegl cv.sparsegl objects. coef() predict() return matrix coefficients predictions \\(\\hat{y}\\) given matrix X lambda respectively. optional s argument may provide specific value \\(\\lambda\\) (necessarily part original sequence), , case cv.sparsegl object, string specifying either \"lambda.min\" \"lambda.1se\".","code":"coef <- coef(fit1, s = c(0.02, 0.03)) predict(fit1, newx = X[100,], s = fit1$lambda[2:3]) #>             s1        s2 #> [1,] -4.071804 -4.091689 predict(fit_l1, newx = X[100,], s = \"lambda.1se\") #>             s1 #> [1,] -15.64857 print(fit1) #>  #> Call:  sparsegl(x = X, y = y, group = groups)  #>  #> Summary of Lambda sequence: #>          lambda index nnzero active_grps #> Max.    0.62948     1      0           0 #> 3rd Qu. 0.19676    26     20           4 #> Median  0.06443    50     19           4 #> 1st Qu. 0.02014    75     25           5 #> Min.    0.00629   100    111          23"},{"path":"https://dajmcdon.github.io/sparsegl/articles/sparsegl.html","id":"estimate_risk","dir":"Articles","previous_headings":"","what":"estimate_risk()","title":"Getting started with sparsegl","text":"extremely large data sets, cross validation may slow tuning parameter selection. function uses degrees freedom calculate various information criteria. function uses “unknown variance” version likelihood. implemented Gaussian regression. constant ignored (stats::extractAIC()). object: fitted sparsegl object. type: three types penalty used calculation: AIC (Akaike information criterion): \\(2 df / n\\) BIC (Bayesian information criterion): \\(2 df\\log(n) / n\\) GCV (Generalized cross validation): \\(-2\\log(1 - df / n)\\) df degree--freedom, n sample size. approx_df: indicates approximation correct degree--freedom penalty parameter \\(\\lambda\\) used. Default FALSE program compute unbiased estimate exact degree--freedom. df component sparsegl object approximation (albeit fairly accurate one) actual degrees--freedom. However, computing exact value requires inverting portion \\(\\mathbf{X}^\\top \\mathbf{X}\\). computation may take time (default computes exact df). details formula, see (Vaiter, Deledalle, Peyré, et al., 2012).1","code":"risk <- estimate_risk(fit1, X, approx_df = FALSE)"},{"path":"https://dajmcdon.github.io/sparsegl/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel J. McDonald. Author, maintainer. Xiaoxuan Liang. Author. Anibal Solón Heinsfeld. Author. Aaron Cohen. Author. Yi Yang. Contributor. Hui Zou. Contributor. Jerome Friedman. Contributor. Trevor Hastie. Contributor. Rob Tibshirani. Contributor. Balasubramanian Narasimhan. Contributor. Kenneth Tay. Contributor. Noah Simon. Contributor. Junyang Qian. Contributor. James Yang. Contributor.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"McDonald D, Liang X, Solón Heinsfeld , Cohen (2023). sparsegl: Sparse Group Lasso. https://github.com/dajmcdon/sparsegl/, https://dajmcdon.github.io/sparsegl/.","code":"@Manual{,   title = {sparsegl: Sparse Group Lasso},   author = {Daniel J. McDonald and Xiaoxuan Liang and Anibal {Solón Heinsfeld} and Aaron Cohen},   year = {2023},   note = {https://github.com/dajmcdon/sparsegl/, https://dajmcdon.github.io/sparsegl/}, }"},{"path":"https://dajmcdon.github.io/sparsegl/index.html","id":"r-package-sparsegl","dir":"","previous_headings":"","what":"Sparse Group Lasso","title":"Sparse Group Lasso","text":"goal sparsegl fit regularization paths sparse group-lasso penalized learning problems. model typically fit sequence regularization parameters λ. estimators minimize  − ℓ(β|y, X)+λ(1−α)∑g ∈ G||βg||2+λα||β||1. main focus package case loglikelihood corresponds Gaussian logistic regression. also provide ability fit arbitrary GLMs using stats::family() objects.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Sparse Group Lasso","text":"can install released version sparsegl CRAN : can install development version Github :","code":"install.packages(\"sparsegl\") # install.packages(\"remotes\") remotes::install_github(\"dajmcdon/sparsegl\")"},{"path":"https://dajmcdon.github.io/sparsegl/index.html","id":"minimal-example","dir":"","previous_headings":"","what":"Minimal Example","title":"Sparse Group Lasso","text":"","code":"set.seed(1010) n <- 100 p <- 200 X <- matrix(data = rnorm(n*p, mean = 0, sd = 1), nrow = n, ncol = p) eps <- rnorm(n, mean = 0, sd = 1) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0),                 rep(-5, 5), c(2, -3, 8, 0, 0), rep(0, (p - 20))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) plot(fit1, y_axis = \"coef\", x_axis = \"penalty\", add_legend = FALSE)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"function etracts coefficients cross-validated sparsegl() model, using stored \"sparsegl.fit\" object, optimal value chosen lambda.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"","code":"# S3 method for cv.sparsegl coef(object, s = c(\"lambda.1se\", \"lambda.min\"), ...)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"object Fitted cv.sparsegl() object. s Value(s) penalty parameter lambda coefficients desired. Default single value s = \"lambda.1se\" stored CV object (corresponding largest value lambda CV error estimate within 1 standard error minimum). Alternatively s = \"lambda.min\" can used (corresponding minimum cross validation error estimate). s numeric, taken value(s) lambda used. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"coefficients requested value(s) lambda.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.cv.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract coefficients from a cv.sparsegl object. — coef.cv.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) cv_fit <- cv.sparsegl(X, y, groups) coef(cv_fit, s = c(0.02, 0.03)) #> 21 x 2 sparse Matrix of class \"dgCMatrix\" #>                     s1          s2 #> (Intercept)  0.1504331  0.15289247 #> V1           4.9015381  4.82535869 #> V2           4.7134519  4.55702581 #> V3           4.7306856  4.62075459 #> V4           4.7605903  4.57026970 #> V5           4.8124095  4.62042660 #> V6           4.7809008  4.56297635 #> V7          -4.7065510 -4.49408665 #> V8           2.1502603  2.03858304 #> V9           0.2173242  0.21345722 #> V10         -0.1104652 -0.05639834 #> V11         -4.8293588 -4.71718443 #> V12         -4.6952743 -4.68117764 #> V13         -4.7775526 -4.62022585 #> V14         -4.7929275 -4.72391648 #> V15         -4.7744801 -4.71223628 #> V16          .          .          #> V17          .          .          #> V18          .          .          #> V19          .          .          #> V20          .          ."},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract model coefficients from a sparsegl object. — coef.sparsegl","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"Computes coefficients requested value(s) lambda sparsegl() object.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"","code":"# S3 method for sparsegl coef(object, s = NULL, ...)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"object Fitted sparsegl() object. s Value(s) penalty parameter lambda coefficients required. Default entire sequence. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"coefficients requested values lambda.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"s new vector lambda values predictions requested. s lambda sequence used fitting model, coef function use linear interpolation make predictions. new values interpolated using fraction coefficients left right lambda indices.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/coef.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract model coefficients from a sparsegl object. — coef.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) coef(fit1, s = c(0.02, 0.03)) #> 21 x 2 sparse Matrix of class \"dgCMatrix\" #>                      s1          s2 #> (Intercept) -0.14790743 -0.16647513 #> V1           4.56770700  4.41814708 #> V2           5.04038698  4.94835647 #> V3           4.59302641  4.41141272 #> V4           4.49073961  4.27587463 #> V5           4.79188300  4.66979480 #> V6           4.36282390  4.13787841 #> V7          -4.59391046 -4.43011867 #> V8           2.01127636  2.02016369 #> V9          -0.19106933 -0.26474716 #> V10          0.03096227  0.01900305 #> V11         -4.77003138 -4.64466940 #> V12         -4.77555835 -4.66691712 #> V13         -4.46328548 -4.25029807 #> V14         -4.53481835 -4.31770123 #> V15         -4.88797974 -4.80450495 #> V16          .           .          #> V17          .           .          #> V18          .           .          #> V19          .           .          #> V20          .           ."},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation for a sparsegl object. — cv.sparsegl","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"Performs k-fold cross-validation sparsegl(). function largely similar glmnet::cv.glmnet().","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"","code":"cv.sparsegl(   x,   y,   group = NULL,   family = c(\"gaussian\", \"binomial\"),   lambda = NULL,   pred.loss = c(\"default\", \"mse\", \"deviance\", \"mae\", \"misclass\"),   nfolds = 10,   foldid = NULL,   weights = NULL,   offset = NULL,   ... )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"x Double. matrix predictors, dimension \\(n \\times p\\); row vector measurements column feature. Objects class Matrix::sparseMatrix supported. y Double/Integer/Factor. response variable. Quantitative family=\"gaussian\" exponential families. family=\"binomial\" either factor two levels vector integers taking 2 unique values. factor, last level alphabetical order target class. group Integer. vector consecutive integers describing grouping coefficients (see example ). family Character function. Specifies generalized linear model use. Valid options : \"gaussian\" - least squares loss (regression, default), \"binomial\" - logistic loss (classification) type, valid stats::family() object may passed. Note generally much slower estimate built-options passed strings. example, family = \"gaussian\" family = gaussian() produce results, first much faster. lambda user supplied lambda sequence. default, NULL results automatic computation based nlambda, smallest value lambda give null model (coefficient estimates equal zero), lambda.factor. Supplying value lambda overrides behaviour. likely better supply decreasing sequence lambda values single (small) value. supplied, user-defined lambda sequence automatically sorted decreasing order. pred.loss Loss use cross-validation error. Valid options : \"default\" deviance (mse regression deviance otherwise) \"mse\" mean square error \"deviance\" default (mse Gaussian regression, negative log-likelihood otherwise) \"mae\" mean absolute error, can apply family \"misclass\" classification , misclassification error. nfolds Number folds - default 10. Although nfolds can large sample size (leave-one-CV), recommended large datasets. Smallest value allowable nfolds = 3. foldid optional vector values 1 nfolds identifying fold observation . supplied, nfolds can missing. weights Double vector. Optional observation weights. can used stats::family() object. offset Double vector. Optional offset (constant predictor without corresponding coefficient). can used stats::family() object. ... Additional arguments sparsegl().","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"object class cv.sparsegl() returned, list components describing cross-validation error. lambda values lambda used fits. cvm mean cross-validated error - vector length length(lambda). cvsd Estimate standard error cvm. cvupper Upper curve = cvm + cvsd. cvlower Lower curve = cvm - cvsd. name text string indicating type measure (plotting purposes). nnzero number non-zero coefficients lambda active_grps number active groups lambda sparsegl.fit fitted sparsegl() object full data. lambda.min optimal value lambda gives minimum cross validation error cvm. lambda.1se largest value lambda error within 1 standard error minimum. call function call.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"function runs sparsegl() nfolds + 1 times; first get lambda sequence, remainder compute fit folds omitted. average error standard error folds computed.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/cv.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation for a sparsegl object. — cv.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) cv_fit <- cv.sparsegl(X, y, groups)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate information criteria. — estimate_risk","title":"Calculate information criteria. — estimate_risk","text":"function uses degrees freedom calculate various information criteria. function uses \"unknown variance\" version likelihood. implemented Gaussian regression. constant ignored (stats::extractAIC()).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate information criteria. — estimate_risk","text":"","code":"estimate_risk(object, x, type = c(\"AIC\", \"BIC\", \"GCV\"), approx_df = FALSE)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate information criteria. — estimate_risk","text":"object fitted object call sparsegl(). x Matrix. matrix predictors used estimate sparsegl object. May missing approx_df = TRUE. type one AIC, BIC, GCV. approx_df df component sparsegl object approximation (albeit fairly accurate one) actual degrees--freedom. However, exact value requires inverting portion X'X. computation may take time (default computes exact df).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate information criteria. — estimate_risk","text":"data.frame many rows object$lambda. contains columns lambda, df, requested risk types.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate information criteria. — estimate_risk","text":"Vaiter S, Deledalle C, Peyré G, Fadili J, Dossal C. (2012). Degrees Freedom Group Lasso General Design. https://arxiv.org/pdf/1212.6478.pdf.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/estimate_risk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate information criteria. — estimate_risk","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) estimate_risk(fit1, type = \"AIC\", approx_df = TRUE) #>           lambda        df       AIC #> s0  4.901929e-01  0.000000 5.6029624 #> s1  4.466455e-01  5.366885 5.7035111 #> s2  4.069668e-01 13.834569 5.7600237 #> s3  3.708130e-01 15.356566 5.6685303 #> s4  3.378710e-01 16.120759 5.5675803 #> s5  3.078554e-01 23.128045 5.5558872 #> s6  2.805064e-01 24.385359 5.4085547 #> s7  2.555870e-01 25.054194 5.2482437 #> s8  2.328813e-01 25.476375 5.0819927 #> s9  2.121928e-01 25.768449 4.9123249 #> s10 1.933422e-01 25.982465 4.7404676 #> s11 1.761662e-01 26.145630 4.5671208 #> s12 1.605161e-01 26.273682 4.3928295 #> s13 1.462563e-01 26.376451 4.2179517 #> s14 1.332633e-01 26.460401 4.0428071 #> s15 1.214245e-01 26.529965 3.8677285 #> s16 1.106375e-01 26.588305 3.6929141 #> s17 1.008088e-01 26.637718 3.5186864 #> s18 9.185320e-02 26.679926 3.3453432 #> s19 8.369322e-02 26.716243 3.1732045 #> s20 7.625814e-02 26.747687 3.0026203 #> s21 6.948358e-02 26.775061 2.8339759 #> s22 6.331085e-02 26.799007 2.6676974 #> s23 5.768649e-02 26.820041 2.5042537 #> s24 5.256178e-02 26.838588 2.3441584 #> s25 4.789234e-02 26.854995 2.1879668 #> s26 4.363771e-02 26.869551 2.0362711 #> s27 3.976106e-02 26.882499 1.8896895 #> s28 3.622880e-02 26.894043 1.7488523 #> s29 3.301033e-02 26.904358 1.6143819 #> s30 3.007778e-02 26.913590 1.4870071 #> s31 2.740575e-02 26.921869 1.3669780 #> s32 2.497110e-02 26.929303 1.2548845 #> s33 2.275274e-02 26.935989 1.1510634 #> s34 2.073145e-02 26.942008 1.0557195 #> s35 1.888972e-02 26.947433 0.9689139 #> s36 1.721161e-02 26.952327 0.8905597 #> s37 1.568258e-02 26.956748 0.8204291 #> s38 1.428938e-02 26.960742 0.7581685 #> s39 1.301995e-02 26.964356 0.7033206 #> s40 1.186330e-02 26.967626 0.6554754 #> s41 1.080939e-02 26.970588 0.6137851 #> s42 9.849118e-03 26.973271 0.5777827 #> s43 8.974149e-03 33.803065 0.6775319 #> s44 8.176911e-03 34.539078 0.6606819 #> s45 7.450496e-03 34.931566 0.6412934 #> s46 6.788615e-03 35.175323 0.6228607 #> s47 6.185533e-03 35.340836 0.6062998 #> s48 5.636027e-03 35.460110 0.5917983 #> s49 5.135338e-03 35.549784 0.5792814 #> s50 4.679129e-03 35.619371 0.5685759 #> s51 4.263448e-03 35.674679 0.5595342 #> s52 3.884695e-03 35.719540 0.5518333 #> s53 3.539589e-03 35.756483 0.5453437 #> s54 3.225142e-03 35.787298 0.5398926 #> s55 2.938629e-03 35.813281 0.5353259 #> s56 2.677570e-03 35.835388 0.5315087 #> s57 2.439702e-03 35.854344 0.5283245 #> s58 2.222965e-03 35.870707 0.5256733 #> s59 2.025483e-03 35.884913 0.5234696 #> s60 1.845545e-03 35.897309 0.5216409 #> s61 1.681592e-03 35.908173 0.5201259 #> s62 1.532204e-03 35.917733 0.5188727 #> s63 1.396087e-03 35.926162 0.5178561 #> s64 1.272062e-03 35.933639 0.5170007 #> s65 1.159056e-03 35.940279 0.5162958 #> s66 1.056089e-03 35.946191 0.5157166 #> s67 9.622686e-04 35.951466 0.5152416 #> s68 8.767833e-04 35.956181 0.5148528 #> s69 7.988923e-04 35.960396 0.5145499 #> s70 7.279209e-04 35.964185 0.5142904 #> s71 6.632544e-04 35.967589 0.5140784 #> s72 6.043327e-04 35.970652 0.5139067 #> s73 5.506455e-04 35.973400 0.5137849 #> s74 5.017276e-04 35.975886 0.5136740 #> s75 4.571555e-04 35.978130 0.5135829 #> s76 4.165431e-04 35.980158 0.5135098 #> s77 3.795386e-04 35.981990 0.5134519 #> s78 3.458214e-04 35.983648 0.5134064 #> s79 3.150996e-04 35.985148 0.5133711 #> s80 2.871070e-04 35.986507 0.5133440 #> s81 2.616012e-04 35.987733 0.5133344 #> s82 2.383613e-04 35.988853 0.5133103 #> s83 2.171859e-04 35.989862 0.5133059 #> s84 1.978917e-04 35.990785 0.5132916 #> s85 1.803116e-04 35.991616 0.5132911 #> s86 1.642932e-04 35.992373 0.5132893 #> s87 1.496978e-04 35.993061 0.5132878 #> s88 1.363991e-04 35.993686 0.5132873 #> s89 1.242818e-04 35.994254 0.5132876 #> s90 1.132409e-04 35.994771 0.5132887 #> s91 1.031809e-04 35.995240 0.5132904 #> s92 9.401460e-05 35.995667 0.5132925 #> s93 8.566260e-05 35.996056 0.5132950 #> s94 7.805257e-05 35.996409 0.5132976 #> s95 7.111860e-05 35.996731 0.5133003 #> s96 6.480062e-05 35.997023 0.5133031 #> s97 5.904391e-05 35.997289 0.5133059 #> s98 5.379861e-05 35.997531 0.5133086 #> s99 4.901929e-05 35.997752 0.5133113"},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate common norms — zero_norm","title":"Calculate common norms — zero_norm","text":"Calculate different norms vectors without grouping structures.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate common norms — zero_norm","text":"","code":"zero_norm(x)  one_norm(x)  two_norm(x)  grouped_zero_norm(x, gr)  grouped_one_norm(x, gr)  grouped_two_norm(x, gr)  grouped_sp_norm(x, gr, asparse)  gr_one_norm(x, gr)  gr_two_norm(x, gr)  sp_group_norm(x, gr, asparse = 0.05)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate common norms — zero_norm","text":"x numeric vector. gr integer (factor) vector length x. asparse Scalar. weight put l1 norm calculating group norm.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate common norms — zero_norm","text":"numeric scalar vector","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Calculate common norms — zero_norm","text":"zero_norm(): l0-norm (number nonzero entries). one_norm(): l1-norm (Absolute-value norm). two_norm(): l2-norm (Euclidean norm). grouped_zero_norm(): vector group-wise l0-norms. grouped_one_norm(): vector group-wise l1-norms. grouped_two_norm(): vector group-wise l2-norms. grouped_sp_norm(): vector length unique(gr) consisting asparse convex combination l1 l2-norm group. gr_one_norm(): l1-norm norm vector (scalar). gr_two_norm(): sum group-wise l2-norms vector (scalar). sp_group_norm(): sum asparse convex combination group l1 l2-norms vectors (scalar).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/grouped_sp_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate common norms — zero_norm","text":"","code":"x <- c(rep(-1, 5), rep(0, 5), rep(1,5)) gr <- c(rep(1,5), rep(2,5), rep(3,5)) asparse <- 0.05 grouped_sp_norm(x, gr, asparse) #> [1] 2.374265 0.000000 2.374265"},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":null,"dir":"Reference","previous_headings":"","what":"Create starting values for iterative reweighted least squares — make_irls_warmup","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"function may used create potentially valid starting values calling sparsegl() stats::family() object. typically necessary call function (used internally create ), cases, especially custom generalized linear models, may improve performance.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"","code":"make_irls_warmup(nobs, nvars, b0 = 0, beta = double(nvars), r = double(nobs))"},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"nobs Number observations response (rows x). nvars Number columns x b0 Scalar. Initial value intercept. beta Vector. Initial values coefficients. Must length nvars (scalar). r Vector. Initial values deviance residuals. Must length nobs (scalar).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"List class irlsspgl_warmup","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/make_irls_warmup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create starting values for iterative reweighted least squares — make_irls_warmup","text":"Occasionally, irls fitting routine may fail admonition create valid starting values.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://dajmcdon.github.io/sparsegl/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"Plots cross-validation curve, upper lower standard deviation curves, function lambda values used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"","code":"# S3 method for cv.sparsegl plot(x, log_axis = c(\"xy\", \"x\", \"y\", \"none\"), sign.lambda = 1, ...)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"x Fitted \"cv.sparsegl\" object, produced cv.sparsegl(). log_axis Apply log scaling requested axes. sign.lambda Either plot log(lambda) (default) reverse sign.lambda < 0. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"ggplot2::ggplot() plot produced. Additional user modifications may added desired.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.cv.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot cross-validation curves produced from a cv.sparsegl object. — plot.cv.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) cv_fit <- cv.sparsegl(X, y, groups) plot(cv_fit)"},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot solution paths from a sparsegl object. — plot.sparsegl","title":"Plot solution paths from a sparsegl object. — plot.sparsegl","text":"Produces coefficient profile plot fitted sparsegl() object. result ggplot2::ggplot(). Additional user modifications can added desired.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot solution paths from a sparsegl object. — plot.sparsegl","text":"","code":"# S3 method for sparsegl plot(   x,   y_axis = c(\"coef\", \"group\"),   x_axis = c(\"lambda\", \"penalty\"),   add_legend = n_legend_values < 20,   ... )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot solution paths from a sparsegl object. — plot.sparsegl","text":"x Fitted \"sparsegl\" object, produced sparsegl(). y_axis Variable y_axis. Either coefficients (default) group norm. x_axis Variable x-axis. Either (log)-lambda sequence (default) value penalty. second case, penalty scaled maximum along path. add_legend Show legend. Often, many groups/predictors, can become overwhelming. default produces legend number groups/predictors less 20. ... used.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/plot.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot solution paths from a sparsegl object. — plot.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) plot(fit1, y_axis = \"coef\", x_axis = \"penalty\")"},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"function makes predictions cross-validated cv.sparsegl() object, using stored sparsegl.fit object, value chosen lambda.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"","code":"# S3 method for cv.sparsegl predict(   object,   newx,   s = c(\"lambda.1se\", \"lambda.min\"),   type = c(\"link\", \"response\", \"coefficients\", \"nonzero\", \"class\"),   ... )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"object Fitted cv.sparsegl() object. newx Matrix new values x predictions made. Must matrix. argument mandatory. s Value(s) penalty parameter lambda coefficients desired. Default single value s = \"lambda.1se\" stored CV object (corresponding largest value lambda CV error estimate within 1 standard error minimum). Alternatively s = \"lambda.min\" can used (corresponding minimum cross validation error estimate). s numeric, taken value(s) lambda used. type Type prediction required. Type \"link\" gives linear predictors \"binomial\"; \"gaussian\" models gives fitted values. Type \"response\" gives predictions scale response (example, fitted probabilities \"binomial\"); \"gaussian\" type \"response\" equivalent type \"link\". Type \"coefficients\" computes coefficients requested values s. Type \"class\" applies \"binomial\" models, produces class label corresponding maximum probability. Type \"nonzero\" returns list indices nonzero coefficients value s. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"matrix vector predicted values.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.cv.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make predictions from a cv.sparsegl object. — predict.cv.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) cv_fit <- cv.sparsegl(X, y, groups) predict(cv_fit, newx = X[50:60, ], s = \"lambda.min\") #>               s1 #>  [1,] -30.790502 #>  [2,]   5.387331 #>  [3,]   7.897686 #>  [4,] -22.208750 #>  [5,] -10.209631 #>  [6,] -14.026117 #>  [7,]  -6.406076 #>  [8,] -34.804563 #>  [9,]   4.921089 #> [10,]  31.029416 #> [11,] -23.042784"},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Make predictions from a sparsegl object. — predict.sparsegl","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"Similar predict methods, function produces fitted values class labels fitted sparsegl object.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"","code":"# S3 method for sparsegl predict(   object,   newx,   s = NULL,   type = c(\"link\", \"response\", \"coefficients\", \"nonzero\", \"class\"),   ... )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"object Fitted sparsegl() model object. newx Matrix new values x predictions made. Must matrix. argument mandatory. s Value(s) penalty parameter lambda predictions required. Default entire sequence used create model. type Type prediction required. Type \"link\" gives linear predictors \"binomial\"; \"gaussian\" models gives fitted values. Type \"response\" gives predictions scale response (example, fitted probabilities \"binomial\"); \"gaussian\" type \"response\" equivalent type \"link\". Type \"coefficients\" computes coefficients requested values s. Type \"class\" applies \"binomial\" models, produces class label corresponding maximum probability. Type \"nonzero\" returns list indices nonzero coefficients value s. ... used.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"object returned depends type.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"s new vector lambda values predictions requested. s lambda sequence used fitting model, coef function use linear interpolation make predictions. new values interpolated using fraction coefficients left right lambda indices.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/predict.sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make predictions from a sparsegl object. — predict.sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit1 <- sparsegl(X, y, group = groups) predict(fit1, newx = X[10, ], s = fit1$lambda[3:5]) #>              s1        s2        s3 #> [1,] -0.8080971 -1.420536 -2.015252"},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":null,"dir":"Reference","previous_headings":"","what":"Regularization paths for sparse group-lasso models — sparsegl","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"Fits regularization paths sparse group-lasso penalized learning problems sequence regularization parameters lambda. Note objective function least squares $$RSS/(2n) + \\lambda penalty$$ Users can also tweak penalty choosing different penalty factor.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"","code":"sparsegl(   x,   y,   group = NULL,   family = c(\"gaussian\", \"binomial\"),   nlambda = 100,   lambda.factor = ifelse(nobs < nvars, 0.01, 1e-04),   lambda = NULL,   pf_group = sqrt(bs),   pf_sparse = rep(1, nvars),   intercept = TRUE,   asparse = 0.05,   standardize = TRUE,   lower_bnd = -Inf,   upper_bnd = Inf,   weights = NULL,   offset = NULL,   warm = NULL,   trace_it = 0,   dfmax = as.integer(max(group)) + 1L,   pmax = min(dfmax * 1.2, as.integer(max(group))),   eps = 1e-08,   maxit = 3e+06 )"},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"x Double. matrix predictors, dimension \\(n \\times p\\); row vector measurements column feature. Objects class Matrix::sparseMatrix supported. y Double/Integer/Factor. response variable. Quantitative family=\"gaussian\" exponential families. family=\"binomial\" either factor two levels vector integers taking 2 unique values. factor, last level alphabetical order target class. group Integer. vector consecutive integers describing grouping coefficients (see example ). family Character function. Specifies generalized linear model use. Valid options : \"gaussian\" - least squares loss (regression, default), \"binomial\" - logistic loss (classification) type, valid stats::family() object may passed. Note generally much slower estimate built-options passed strings. example, family = \"gaussian\" family = gaussian() produce results, first much faster. nlambda number lambda values - default 100. lambda.factor multiplicative factor minimal lambda lambda sequence, min(lambda) = lambda.factor * max(lambda). max(lambda) smallest value lambda coefficients zero. default depends relationship \\(n\\) (number rows matrix predictors) \\(p\\) (number predictors). \\(n \\geq p\\), default 0.0001.  \\(n < p\\), default 0.01. small value lambda.factor lead saturated fit. argument effect user-defined lambda sequence. lambda user supplied lambda sequence. default, NULL results automatic computation based nlambda, smallest value lambda give null model (coefficient estimates equal zero), lambda.factor. Supplying value lambda overrides behaviour. likely better supply decreasing sequence lambda values single (small) value. supplied, user-defined lambda sequence automatically sorted decreasing order. pf_group Penalty factor groups, vector length total number groups. Separate penalty weights can applied group \\(\\beta\\)s allow differential shrinkage. Can 0 groups, implies shrinkage, results group always included model (depending pf_sparse). Default value entry square-root corresponding size group. pf_sparse Penalty factor l1-norm, vector length total number columns x. value corresponds one predictor Can 0 predictors, implies predictor receive group penalty. intercept Whether include intercept model. Default TRUE. asparse relative weight put \\(\\ell_1\\)-norm sparse group lasso. Default 0.05 (resulting 0.95 \\(\\ell_2\\)-norm). standardize Logical flag variable standardization (scaling) prior fitting model. Default TRUE. lower_bnd Lower bound coefficient values, vector length 1 length number groups. Must non-positive numbers . Default value entry -Inf. upper_bnd Upper coefficient values, vector length 1 length number groups. Must non-negative numbers . Default value entry Inf. weights Double vector. Optional observation weights. can used stats::family() object. offset Double vector. Optional offset (constant predictor without corresponding coefficient). can used stats::family() object. warm List created make_irls_warmup(). can used stats::family() object, typically necessary even . trace_it Scalar integer. Larger values print output irls loop. Typical values 0 (printing), 1 (printing progress bar), 2 (detailed printing). can used stats::family() object. dfmax Limit maximum number groups model. Default limit. pmax Limit maximum number groups ever nonzero. example group enters model, matter many times exits re-enters model path, counted . eps Convergence termination tolerance. Defaults value 1e-8. maxit Maximum number outer-loop iterations allowed fixed lambda value. Default 3e8. models converge, consider increasing maxit.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"object S3 class \"sparsegl\". Among list components: call call produced object. b0 Intercept sequence length length(lambda). beta p x length(lambda) sparse matrix coefficients. df number features nonzero coefficients value lambda. dim Dimension coefficient matrix. lambda actual sequence lambda values used. npasses Total number iterations summed lambda values. jerr Error flag, warnings errors, 0 error. group vector consecutive integers describing grouping coefficients. nobs number observations used estimate model. sparsegl() called stats::family() method, may also contain information deviance family used fitting.","code":""},{"path":[]},{"path":"https://dajmcdon.github.io/sparsegl/reference/sparsegl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regularization paths for sparse group-lasso models — sparsegl","text":"","code":"n <- 100 p <- 20 X <- matrix(rnorm(n * p), nrow = n) eps <- rnorm(n) beta_star <- c(rep(5, 5), c(5, -5, 2, 0, 0), rep(-5, 5), rep(0, (p - 15))) y <- X %*% beta_star + eps groups <- rep(1:(p / 5), each = 5) fit <- sparsegl(X, y, group = groups)  yp <- rpois(n, abs(X %*% beta_star)) fit_pois <- sparsegl(X, yp, group = groups, family = poisson())"},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":null,"dir":"Reference","previous_headings":"","what":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"dataset containing measurement \"trust\" experts along metrics collected Delphi Group Carnegie Mellon University U.S. COVID-19 Trends Impact Survey, partnership Facebook. particular dataset created one public contingency tables, specifically, breakdown state, age, gender, race/ethnicity published 05 February 2022.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"","code":"trust_experts"},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"data.frame 9759 rows 8 columns trust_experts Real-valued. average pct_trust_covid_info_* * doctors, experts, cdc, govt_health. period Factor. Start date data collection period. 13 monthly periods region Factor. State abbreviation. age Factor. Self-reported age bucket. gender Factor. Self-reported gender. raceethnicity Factor. Self-reported race ethnicity. cli Real-valued. wcli indicator measuring percent circulating Covid-like illness particular region. See Delphi Epidata API complete description. hh_cmnty_cli Real-valued. whh_cmnty_cli indicator measuring percent people reporting illness local community household.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"U.S. COVID-19 Trends Impact Survey. paper describing survey: Joshua . Salomon, Alex Reinhart, Alyssa Bilinski, Eu Jing Chua, Wichada La Motte-Kerr, Minttu M. Rönn, Marissa Reitsma, Katherine Ann Morris, Sarah LaRocca, Tamar Farag, Frauke Kreuter, Roni Rosenfeld, Ryan J. Tibshirani (2021). \"US COVID-19 Trends Impact Survey: Continuous real-time measurement COVID-19 symptoms, risks, protective behaviors, testing, vaccination\", Proceedings National Academy Sciences 118 (51) e2111454118. doi:10.1073/pnas.2111454118 . Public Delphi US CTIS Documentation","code":""},{"path":"https://dajmcdon.github.io/sparsegl/reference/trust_experts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trust in scientific experts during the Covid-19 pandemic — trust_experts","text":"","code":"if (FALSE) { library(splines) library(dplyr) library(magrittr) df <- 10  trust_experts <- trust_experts %>%   mutate(across(     where(is.factor),     ~ set_attr(.x, \"contrasts\", contr.sum(nlevels(.x), FALSE, TRUE))   ))  x <- Matrix::sparse.model.matrix(     ~ 0 + region + age + gender + raceethnicity + period +     bs(cli, df = df) + bs(hh_cmnty_cli, df = df),     data = trust_experts, drop.unused.levels = TRUE)  gr <- sapply(trust_experts, function(x) ifelse(is.factor(x), nlevels(x), NA)) gr <- rep(seq(ncol(trust_experts) - 1), times = c(gr[!is.na(gr)], df, df)) fit <- cv.sparsegl(x, trust_experts$trust_experts, gr) }"},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-100","dir":"Changelog","previous_headings":"","what":"sparsegl 1.0.0","title":"sparsegl 1.0.0","text":"CRAN release: 2022-11-28 Improved documentation Added functionality implement arbitrary stats::family() fitting. Enhanced (corrected) S3 interface predict coef methods.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-050","dir":"Changelog","previous_headings":"","what":"sparsegl 0.5.0","title":"sparsegl 0.5.0","text":"CRAN release: 2022-09-22 Minor internal updates pass additional CRAN checks Refactor documentation Intercept calculation internal Fortran source cases.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-040","dir":"Changelog","previous_headings":"","what":"sparsegl 0.4.0","title":"sparsegl 0.4.0","text":"CRAN release: 2022-09-05 Add option weight individual coefficients l1 penalty. Remove coercions type (<matrix>, \"dgCMatrix\"). deprecated Matrix>=1.4-2 Warn CRAN checks. Compute MSE internally Fortran family = \"Gaussian\". Avoids creation potentially large matrix predicted values purposes risk estimation. Revise estimate_risk() signature. Now x optional y required.","code":""},{"path":"https://dajmcdon.github.io/sparsegl/news/index.html","id":"sparsegl-030","dir":"Changelog","previous_headings":"","what":"sparsegl 0.3.0","title":"sparsegl 0.3.0","text":"CRAN release: 2022-03-07 Initial version CRAN.","code":""}]
